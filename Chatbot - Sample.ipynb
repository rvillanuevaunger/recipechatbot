{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8562ce4a",
   "metadata": {},
   "source": [
    "recipes-telegram-bot/src/recommendation_engine/data.py /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125dcdd6",
   "metadata": {},
   "source": [
    "1. Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59e49343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_CUISINE_PATH = \"data/cuisine_data/\"\n",
    "DATA_RECIPES_PATH = \"data/recipes_data/\"\n",
    "\n",
    "def import_data():\n",
    "    train = pd.read_json(os.path.join(DATA_CUISINE_PATH, 'train.json'))\n",
    "    test = pd.read_json(os.path.join(DATA_CUISINE_PATH, 'test.json'))\n",
    "    return pd.concat([train,test],axis=0)\n",
    "\n",
    "def import_recipes_main():\n",
    "    data_path_ar = os.path.join(DATA_RECIPES_PATH, \"recipes_raw_nosource_ar.json\")\n",
    "    data_path_epi = os.path.join(DATA_RECIPES_PATH, \"recipes_raw_nosource_epi.json\")\n",
    "    data_path_fn = os.path.join(DATA_RECIPES_PATH, \"recipes_raw_nosource_fn.json\")\n",
    "    \n",
    "    data =  pd.concat([pd.read_json(data_path_ar, orient='index'), pd.read_json(data_path_epi, orient='index'), pd.read_json(data_path_fn, orient='index')])\n",
    "    data = data.reset_index()\n",
    "    data = data.drop(columns=['picture_link', 'index'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2b64780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_recipes_main_test():\n",
    "    all_recipes = pd.read_json('./data/recipes_data/recipes_raw_nosource_allrecipes.json', orient='index')\n",
    "    epicurious = pd.read_json('./data/recipes_data/recipes_raw_nosource_epicurious.json', orient='index')\n",
    "    food_network = pd.read_json('./data/recipes_data/recipes_raw_nosource_foodnetwork.json', orient='index')\n",
    "    recipes = pd.concat([all_recipes, epicurious, food_network], axis=0)\n",
    "    \n",
    "    recipes = recipes.reset_index()\n",
    "    recipes = recipes.drop(columns=['index', 'picture_link'])\n",
    "    return recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7823aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recipes = pd.read_json('./data/recipes_data/recipes_raw_nosource_allrecipes.json', orient='index')\n",
    "\n",
    "epicurious = pd.read_json('./data/recipes_data/recipes_raw_nosource_epicurious.json', orient='index')\n",
    "\n",
    "food_network = pd.read_json('./data/recipes_data/recipes_raw_nosource_foodnetwork.json', orient='index')\n",
    "\n",
    "recipes = pd.concat([all_recipes, epicurious, food_network], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "779d11a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slow Cooker Chicken and Dumplings</td>\n",
       "      <td>[4 skinless, boneless chicken breast halves AD...</td>\n",
       "      <td>Place the chicken, butter, soup, and onion in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Awesome Slow Cooker Pot Roast</td>\n",
       "      <td>[2 (10.75 ounce) cans condensed cream of mushr...</td>\n",
       "      <td>In a slow cooker, mix cream of mushroom soup, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown Sugar Meatloaf</td>\n",
       "      <td>[1/2 cup packed brown sugar ADVERTISEMENT, 1/2...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Chocolate Chip Cookies</td>\n",
       "      <td>[1 cup butter, softened ADVERTISEMENT, 1 cup w...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homemade Mac and Cheese Casserole</td>\n",
       "      <td>[8 ounces whole wheat rotini pasta ADVERTISEME...</td>\n",
       "      <td>Preheat oven to 350 degrees F. Line a 2-quart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124642</th>\n",
       "      <td>Summer Corn Salad</td>\n",
       "      <td>[4 ears fresh corn, 2 heads Belgian endive, 2 ...</td>\n",
       "      <td>Watch how to make this recipe.\\nPreheat a gril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124643</th>\n",
       "      <td>Zucchini Stuffed Tomatoes</td>\n",
       "      <td>[4 large plum tomatoes, Salt and sugar, 1 1/2 ...</td>\n",
       "      <td>Preheat the broiler. Cut the tomatoes in 1/2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124644</th>\n",
       "      <td>Pepper Pasta Quick Cook</td>\n",
       "      <td>[3 tablespoons olive oil, 2 tablespoons unsalt...</td>\n",
       "      <td>Heat the oil and butter in a large skillet ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124645</th>\n",
       "      <td>Chocolate Cake with Armagnac Ice Cream</td>\n",
       "      <td>[8 ounces butter, 8 ounces bittersweet chocola...</td>\n",
       "      <td>Preheat oven to 350 degrees. On the top half o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124646</th>\n",
       "      <td>Crabby Bisque</td>\n",
       "      <td>[3 (10.5-ounce) cans restaurant-style condense...</td>\n",
       "      <td>Watch how to make this recipe.\\nIn a medium sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124647 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0            Slow Cooker Chicken and Dumplings   \n",
       "1                Awesome Slow Cooker Pot Roast   \n",
       "2                         Brown Sugar Meatloaf   \n",
       "3                  Best Chocolate Chip Cookies   \n",
       "4            Homemade Mac and Cheese Casserole   \n",
       "...                                        ...   \n",
       "124642                       Summer Corn Salad   \n",
       "124643               Zucchini Stuffed Tomatoes   \n",
       "124644                 Pepper Pasta Quick Cook   \n",
       "124645  Chocolate Cake with Armagnac Ice Cream   \n",
       "124646                           Crabby Bisque   \n",
       "\n",
       "                                              ingredients  \\\n",
       "0       [4 skinless, boneless chicken breast halves AD...   \n",
       "1       [2 (10.75 ounce) cans condensed cream of mushr...   \n",
       "2       [1/2 cup packed brown sugar ADVERTISEMENT, 1/2...   \n",
       "3       [1 cup butter, softened ADVERTISEMENT, 1 cup w...   \n",
       "4       [8 ounces whole wheat rotini pasta ADVERTISEME...   \n",
       "...                                                   ...   \n",
       "124642  [4 ears fresh corn, 2 heads Belgian endive, 2 ...   \n",
       "124643  [4 large plum tomatoes, Salt and sugar, 1 1/2 ...   \n",
       "124644  [3 tablespoons olive oil, 2 tablespoons unsalt...   \n",
       "124645  [8 ounces butter, 8 ounces bittersweet chocola...   \n",
       "124646  [3 (10.5-ounce) cans restaurant-style condense...   \n",
       "\n",
       "                                             instructions  \n",
       "0       Place the chicken, butter, soup, and onion in ...  \n",
       "1       In a slow cooker, mix cream of mushroom soup, ...  \n",
       "2       Preheat oven to 350 degrees F (175 degrees C)....  \n",
       "3       Preheat oven to 350 degrees F (175 degrees C)....  \n",
       "4       Preheat oven to 350 degrees F. Line a 2-quart ...  \n",
       "...                                                   ...  \n",
       "124642  Watch how to make this recipe.\\nPreheat a gril...  \n",
       "124643  Preheat the broiler. Cut the tomatoes in 1/2 c...  \n",
       "124644  Heat the oil and butter in a large skillet ove...  \n",
       "124645  Preheat oven to 350 degrees. On the top half o...  \n",
       "124646  Watch how to make this recipe.\\nIn a medium sa...  \n",
       "\n",
       "[124647 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_recipes_main_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240c814",
   "metadata": {},
   "source": [
    "recipes-telegram-bot/src/recommendation_engine/feature_engineering.py /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0c03c",
   "metadata": {},
   "source": [
    "2. Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0fb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/reina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/reina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, model_selection, pipeline, manifold, preprocessing\n",
    "\n",
    "#from src.recommendation_engine.data import import_data\n",
    "\n",
    "additional_stop_words = [\"advertisement\", \"advertisements\",\n",
    "                         \"cup\", \"cups\",\n",
    "                         \"tablespoon\", \"tablespoons\", \n",
    "                         \"teaspoon\", \"teaspoons\", \n",
    "                         \"ounce\", \"ounces\",\n",
    "                         \"salt\", \n",
    "                         \"pepper\", \n",
    "                         \"pound\", \"pounds\",\n",
    "                         ]\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e31b40",
   "metadata": {},
   "source": [
    "3. Pre-Processing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfeab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "\n",
    "    ## Remove digits\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    ## remove mutliple space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f095f1",
   "metadata": {},
   "source": [
    "4. Pre-Process Data: Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "242a884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    dataset = import_data() # cuisine\n",
    "\n",
    "    def processing(row):\n",
    "        ls = row['ingredients']\n",
    "        return ' '.join(ls)\n",
    "\n",
    "    dataset['ingredients'] = dataset.apply(lambda x: processing(x), axis=1)\n",
    "    dataset.dropna(inplace=True)\n",
    "    dataset = dataset.drop(columns=['id']).reset_index(drop=True)\n",
    "\n",
    "    stop_word_list = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # Extend list of stop words\n",
    "    stop_word_list.extend(additional_stop_words)\n",
    "\n",
    "    dataset[\"ingredients_query\"] = dataset[\"ingredients\"].apply(lambda x: \n",
    "          utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, \n",
    "          lst_stopwords=stop_word_list))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8289238a",
   "metadata": {},
   "source": [
    "5. Create Embeddings from Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a519bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(dataset):\n",
    "    ## Tf-Idf (advanced variant of BoW)\n",
    "    vectorizer = feature_extraction.text.TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "\n",
    "    corpus = dataset[\"ingredients_query\"]\n",
    "    vectorizer.fit(corpus)\n",
    "    embedded_ingredients = vectorizer.transform(corpus)\n",
    "    dic_vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "    ## Chi squarred correlation embeddings reduction\n",
    "    labels = dataset[\"cuisine\"]\n",
    "    names = vectorizer.get_feature_names()\n",
    "    p_value_limit = 0.95\n",
    "    dtf_features = pd.DataFrame()\n",
    "\n",
    "    for cat in np.unique(labels):\n",
    "        chi2, p = feature_selection.chi2(embedded_ingredients, labels==cat)\n",
    "        dtf_features = dtf_features.append(pd.DataFrame(\n",
    "                       {\"feature\":names, \"score\":1-p, \"labels\":cat}))\n",
    "        dtf_features = dtf_features.sort_values([\"labels\",\"score\"], \n",
    "                        ascending=[True,False])\n",
    "        dtf_features = dtf_features[dtf_features[\"score\"]>p_value_limit]\n",
    "    names = dtf_features[\"feature\"].unique().tolist()\n",
    "\n",
    "    ## Check the main ingredients\n",
    "    for cat in np.unique(labels):\n",
    "        print(\"# {}:\".format(cat))\n",
    "        print(\"  . selected features:\",len(dtf_features[dtf_features[\"labels\"]==cat]))\n",
    "        print(\"  . top features:\", \",\".join(dtf_features[dtf_features[\"labels\"]==cat][\"feature\"].values[:10]))\n",
    "        print(\" \")\n",
    "    \n",
    "    ## New embeddings\n",
    "    vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=names)\n",
    "    vectorizer.fit(corpus)\n",
    "    embedded_ingredients = vectorizer.transform(corpus)\n",
    "    dic_vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83ba94",
   "metadata": {},
   "source": [
    "6. Pre-Process Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cd924fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recipes(data): # Recipes dataset\n",
    "    # list of stopwords\n",
    "    stop_word_list = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # Extend list of stop words\n",
    "    stop_word_list.extend(additional_stop_words)\n",
    "\n",
    "    data[\"ingredients_query\"] = data[\"ingredients\"].apply(lambda x: \n",
    "            utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, \n",
    "            lst_stopwords=stop_word_list))\n",
    "    return data\n",
    "\n",
    "def get_tokenize_text(input_text):\n",
    "    # list of stopwords\n",
    "    stop_word_list = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    # Extend list of stop words\n",
    "    stop_word_list.extend(additional_stop_words)\n",
    "\n",
    "    return utils_preprocess_text(input_text, flg_stemm=False, flg_lemm=True, lst_stopwords=stop_word_list) # same function to pre-process text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ca156",
   "metadata": {},
   "source": [
    "recipes-telegram-bot/src/recommendation_engine/create_model.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3031006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "## for processing\n",
    "import re\n",
    "import nltk\n",
    "## for bag-of-words\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "## model & processing libraries\n",
    "from sklearn import feature_selection\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from sklearn import utils\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pickle\n",
    "## DB accesses\n",
    "import sqlite3 as sq\n",
    "#from src.recommendation_engine.feature_engineering import process_data, create_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8e5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"models/nlp\"\n",
    "MODEL_EMBEDDINGS_PATH = os.path.join(MODEL_PATH, 'similarity_embeddings')\n",
    "CUISINE_CLASSES = ['brazilian','british','cajun_creole','chinese','filipino','french','greek','indian',\n",
    "                   'irish','italian','jamaican','japanese','korean','mexican','moroccan','russian','southern_us',\n",
    "                   'spanish','thai','vietnamese']\n",
    "\n",
    "os.makedirs(MODEL_PATH, exist_ok=True)\n",
    "os.makedirs(MODEL_EMBEDDINGS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0ac876",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save to file in the current working directory\n",
    "def save_pkl(file, pkl_filename):\n",
    "    with open(pkl_filename, 'wb') as pkl_file:\n",
    "        pickle.dump(file, pkl_file)\n",
    "\n",
    "def compute_performances(predicted, predicted_prob, y_test):\n",
    "    \n",
    "    classes = np.unique(y_test)\n",
    "    y_test_array = pd.get_dummies(y_test, drop_first=False).values\n",
    "\n",
    "    ## Accuracy, Precision, Recall\n",
    "    accuracy = metrics.accuracy_score(y_test, predicted)\n",
    "    balance_accuracy = metrics.balanced_accuracy_score(y_test, predicted)\n",
    "    auc = metrics.roc_auc_score(y_test, predicted_prob, \n",
    "                                multi_class=\"ovr\")\n",
    "    print(\"Balanced Accuracy:\",  round(balance_accuracy,2))\n",
    "    print(\"Accuracy:\",  round(accuracy,2))\n",
    "    print(\"Auc:\", round(auc,2))\n",
    "    print(\"Detail:\")\n",
    "    print(metrics.classification_report(y_test, predicted))\n",
    "\n",
    "\n",
    "def create_model_cuisine_predictions():\n",
    "    ## Process data\n",
    "    dataset = process_data() # cuisine dataset\n",
    "\n",
    "    ## Create embeddings\n",
    "    vectorizer = feature_extraction.text.TfidfVectorizer() #create_embeddings(dataset)\n",
    "\n",
    "    ## Model\n",
    "    classifier = LogisticRegressionCV(cv=3,\n",
    "                                      random_state=42,\n",
    "                                      max_iter=300,\n",
    "                                      n_jobs=-1,\n",
    "                                      verbose=1) #naive_bayes.MultinomialNB()\n",
    "\n",
    "    ## pipeline\n",
    "    model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                                (\"classifier\", classifier)])\n",
    "\n",
    "    ## Split the dataset\n",
    "    dataset_train, dataset_test = model_selection.train_test_split(dataset, test_size=0.3, random_state=42)\n",
    "\n",
    "    ## Create embeddings\n",
    "    X_train = dataset_train['ingredients_query']; X_test = dataset_test['ingredients_query'];\n",
    "    y_train = dataset_train['cuisine']; y_test = dataset_test['cuisine']; \n",
    "\n",
    "    ## train classifier\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    ## test\n",
    "    predicted = model.predict(X_test)\n",
    "    predicted_prob = model.predict_proba(X_test)\n",
    "\n",
    "    ## Compute performance of the model\n",
    "    compute_performances(predicted, predicted_prob, y_test)\n",
    "    \n",
    "    ## Save model and vectorizer to disk\n",
    "    save_pkl(model, os.path.join(MODEL_PATH, \"pickle_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "781adf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      "Machine precision = 2.220D-16\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      " N =        52460     M =           10\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.56038D+04    |proj g|=  2.72995D+03\n",
      "\n",
      "\n",
      "At iterate    0    f=  5.56038D+04    |proj g|=  2.72995D+03\n",
      "At iterate    0    f=  5.56008D+04    |proj g|=  2.73000D+03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     29     32      1     0     0   1.056D-01   4.836D+04\n",
      "  F =   48363.792308456083     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     29     32      1     0     0   1.040D-01   4.837D+04\n",
      "  F =   48365.023530004146     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     29     34      1     0     0   1.465D-01   4.836D+04\n",
      "  F =   48358.329136599597     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.83011D+04    |proj g|=  1.93319D+02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.83022D+04    |proj g|=  1.95855D+02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.82953D+04    |proj g|=  1.95457D+02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460      8     10      1     0     0   7.564D-02   4.789D+04\n",
      "  F =   47888.724497472409     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460      8     10      1     0     0   9.213D-02   4.789D+04\n",
      "  F =   47889.431557908581     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460      8     10      1     0     0   7.749D-02   4.788D+04\n",
      "  F =   47881.047253561956     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.74245D+04    |proj g|=  1.88901D+02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.74244D+04    |proj g|=  1.86510D+02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.74146D+04    |proj g|=  1.88560D+02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     15     17      1     0     0   1.919D-01   4.485D+04\n",
      "  F =   44848.824300303386     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     17     18      1     0     0   2.533D-02   4.484D+04\n",
      "  F =   44841.564272176685     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     17     18      1     0     0   1.459D-02   4.483D+04\n",
      "  F =   44830.067001611620     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.22827D+04    |proj g|=  1.46090D+02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.22658D+04    |proj g|=  1.43770D+02\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.22569D+04    |proj g|=  1.43785D+02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     41     47      1     0     0   8.065D-02   3.501D+04\n",
      "  F =   35009.298172277442     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     40     47      1     0     0   2.543D-01   3.499D+04\n",
      "  F =   34990.408689265780     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     43     50      1     0     0   1.115D-01   3.496D+04\n",
      "  F =   34958.687382841301     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.95612D+04    |proj g|=  6.14333D+01\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.95558D+04    |proj g|=  6.07823D+01\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.94963D+04    |proj g|=  5.99734D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  2.23595D+04    |proj g|=  1.44094D+00\n",
      "\n",
      "At iterate   50    f=  2.23381D+04    |proj g|=  3.90576D+00\n",
      "\n",
      "At iterate   50    f=  2.23894D+04    |proj g|=  1.32240D+01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     90     98      1     0     0   3.400D-02   2.236D+04\n",
      "  F =   22358.993533325283     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     87     95      1     0     0   7.523D-02   2.234D+04\n",
      "  F =   22337.506969989459     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460     89     97      1     0     0   3.863D-02   2.239D+04\n",
      "  F =   22388.797972943052     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.76069D+04    |proj g|=  1.60985D+01\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.76187D+04    |proj g|=  1.55577D+01\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.76612D+04    |proj g|=  1.57977D+01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  1.35008D+04    |proj g|=  1.35882D+01\n",
      "\n",
      "At iterate   50    f=  1.35671D+04    |proj g|=  3.15303D+01\n",
      "\n",
      "At iterate   50    f=  1.35968D+04    |proj g|=  2.24418D+01\n",
      "\n",
      "At iterate  100    f=  1.34532D+04    |proj g|=  1.01507D+00\n",
      "\n",
      "At iterate  100    f=  1.35189D+04    |proj g|=  1.12261D+00\n",
      "\n",
      "At iterate  100    f=  1.35400D+04    |proj g|=  1.53418D+00\n",
      "\n",
      "At iterate  150    f=  1.34523D+04    |proj g|=  3.73368D-01\n",
      "\n",
      "At iterate  150    f=  1.35181D+04    |proj g|=  1.63889D-01\n",
      "\n",
      "At iterate  150    f=  1.35389D+04    |proj g|=  6.58645D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    193    202      1     0     0   6.274D-02   1.345D+04\n",
      "  F =   13452.314095598944     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.05313D+04    |proj g|=  3.57529D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    188    204      1     0     0   3.707D-01   1.352D+04\n",
      "  F =   13518.061735133888     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    189    203      1     0     0   3.473D-02   1.354D+04\n",
      "  F =   13538.922285433135     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.06282D+04    |proj g|=  3.36363D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.06370D+04    |proj g|=  3.44556D+00\n",
      "\n",
      "At iterate   50    f=  8.29049D+03    |proj g|=  6.07121D+01\n",
      "\n",
      "At iterate   50    f=  8.41115D+03    |proj g|=  1.12654D+01\n",
      "\n",
      "At iterate   50    f=  8.40649D+03    |proj g|=  1.37756D+01\n",
      "\n",
      "At iterate  100    f=  8.10091D+03    |proj g|=  3.24921D+00\n",
      "\n",
      "At iterate  100    f=  8.20824D+03    |proj g|=  1.71817D+01\n",
      "\n",
      "At iterate  100    f=  8.23178D+03    |proj g|=  1.29175D+01\n",
      "\n",
      "At iterate  150    f=  8.06396D+03    |proj g|=  3.53062D+00\n",
      "\n",
      "At iterate  150    f=  8.17850D+03    |proj g|=  2.52671D+00\n",
      "\n",
      "At iterate  150    f=  8.19267D+03    |proj g|=  6.44058D+00\n",
      "\n",
      "At iterate  200    f=  8.17282D+03    |proj g|=  3.28831D-01\n",
      "\n",
      "At iterate  200    f=  8.05889D+03    |proj g|=  1.29783D+00\n",
      "\n",
      "At iterate  200    f=  8.18697D+03    |proj g|=  3.21069D+00\n",
      "\n",
      "At iterate  250    f=  8.05787D+03    |proj g|=  8.59454D-01\n",
      "\n",
      "At iterate  250    f=  8.17175D+03    |proj g|=  2.40146D-01\n",
      "\n",
      "At iterate  250    f=  8.18603D+03    |proj g|=  1.39352D-01\n",
      "\n",
      "At iterate  300    f=  8.05769D+03    |proj g|=  2.12347D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    327      1     0     0   2.123D-01   8.058D+03\n",
      "  F =   8057.6925631402728     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  300    f=  8.17158D+03    |proj g|=  2.18468D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    318      1     0     0   2.185D-01   8.172D+03\n",
      "  F =   8171.5759462444030     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.31176D+03    |proj g|=  6.90461D-01\n",
      "\n",
      "At iterate  300    f=  8.18582D+03    |proj g|=  4.17599D-01\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    322      1     0     0   4.176D-01   8.186D+03\n",
      "  F =   8185.8225442103358     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.43465D+03    |proj g|=  6.42057D-01\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.45909D+03    |proj g|=  6.82742D-01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reina/.conda/envs/data641/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/reina/.conda/envs/data641/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " This problem is unconstrained.\n",
      "/Users/reina/.conda/envs/data641/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  5.21823D+03    |proj g|=  5.39374D+01\n",
      "\n",
      "At iterate   50    f=  5.35089D+03    |proj g|=  3.58976D+01\n",
      "\n",
      "At iterate   50    f=  5.41283D+03    |proj g|=  1.69990D+01\n",
      "\n",
      "At iterate  100    f=  5.05920D+03    |proj g|=  5.90032D+00\n",
      "\n",
      "At iterate  100    f=  5.17527D+03    |proj g|=  6.08963D+00\n",
      "\n",
      "At iterate  100    f=  5.23183D+03    |proj g|=  1.05174D+01\n",
      "\n",
      "At iterate  150    f=  4.99827D+03    |proj g|=  1.43352D+01\n",
      "\n",
      "At iterate  150    f=  5.16309D+03    |proj g|=  3.22070D+00\n",
      "\n",
      "At iterate  150    f=  5.10791D+03    |proj g|=  4.23869D+00\n",
      "\n",
      "At iterate  200    f=  4.97441D+03    |proj g|=  1.15422D+00\n",
      "\n",
      "At iterate  200    f=  5.13069D+03    |proj g|=  2.95324D+00\n",
      "\n",
      "At iterate  200    f=  5.07874D+03    |proj g|=  6.24578D+00\n",
      "\n",
      "At iterate  250    f=  4.96252D+03    |proj g|=  4.91898D+00\n",
      "\n",
      "At iterate  250    f=  5.11633D+03    |proj g|=  3.27159D+00\n",
      "\n",
      "At iterate  250    f=  5.06525D+03    |proj g|=  1.63184D+00\n",
      "\n",
      "At iterate  300    f=  4.95671D+03    |proj g|=  4.37842D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    324      1     0     0   4.378D+00   4.957D+03\n",
      "  F =   4956.7103407570612     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.00020D+03    |proj g|=  4.37842D+00\n",
      "\n",
      "At iterate  300    f=  5.10903D+03    |proj g|=  2.24247D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    321      1     0     0   2.242D+00   5.109D+03\n",
      "  F =   5109.0262900929483     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  300    f=  5.05863D+03    |proj g|=  1.39585D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    326      1     0     0   1.396D+00   5.059D+03\n",
      "  F =   5058.6301355945288     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.15543D+03    |proj g|=  2.24247D+00\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.07225D+03    |proj g|=  1.39585D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   50    f=  3.59973D+03    |proj g|=  6.58161D+00\n",
      "\n",
      "At iterate   50    f=  3.77906D+03    |proj g|=  9.84665D+00\n",
      "\n",
      "At iterate   50    f=  3.68625D+03    |proj g|=  4.62995D+01\n",
      "\n",
      "At iterate  100    f=  3.44329D+03    |proj g|=  7.95565D+00\n",
      "\n",
      "At iterate  100    f=  3.60750D+03    |proj g|=  1.17806D+01\n",
      "\n",
      "At iterate  100    f=  3.50449D+03    |proj g|=  6.18328D+00\n",
      "\n",
      "At iterate  150    f=  3.37316D+03    |proj g|=  2.48459D+00\n",
      "\n",
      "At iterate  150    f=  3.55395D+03    |proj g|=  5.29341D+00\n",
      "\n",
      "At iterate  150    f=  3.43891D+03    |proj g|=  1.42737D+01\n",
      "\n",
      "At iterate  200    f=  3.32321D+03    |proj g|=  1.32358D+01\n",
      "\n",
      "At iterate  200    f=  3.51003D+03    |proj g|=  2.79918D+01\n",
      "\n",
      "At iterate  200    f=  3.39353D+03    |proj g|=  5.46077D+00\n",
      "\n",
      "At iterate  250    f=  3.29855D+03    |proj g|=  2.01038D+00\n",
      "\n",
      "At iterate  250    f=  3.36861D+03    |proj g|=  5.62755D+00\n",
      "\n",
      "At iterate  250    f=  3.47758D+03    |proj g|=  4.72530D+00\n",
      "\n",
      "At iterate  300    f=  3.28290D+03    |proj g|=  5.78711D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    318      1     0     0   5.787D+00   3.283D+03\n",
      "  F =   3282.9019034351240     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.80678D+03    |proj g|=  5.78711D+00\n",
      "\n",
      "At iterate  300    f=  3.35194D+03    |proj g|=  5.62840D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    320      1     0     0   5.628D+00   3.352D+03\n",
      "  F =   3351.9351144108914     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  300    f=  3.45299D+03    |proj g|=  2.57048D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    324      1     0     0   2.570D+00   3.453D+03\n",
      "  F =   3452.9856882519744     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.81624D+03    |proj g|=  5.62840D+00\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =        52460     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.02355D+03    |proj g|=  2.57048D+00\n",
      "\n",
      "At iterate   50    f=  2.78529D+03    |proj g|=  4.04669D+00\n",
      "\n",
      "At iterate   50    f=  2.99861D+03    |proj g|=  3.45571D+00\n",
      "\n",
      "At iterate   50    f=  2.79375D+03    |proj g|=  2.86910D+00\n",
      "\n",
      "At iterate  100    f=  2.70123D+03    |proj g|=  8.04803D+00\n",
      "\n",
      "At iterate  100    f=  2.74291D+03    |proj g|=  4.79262D+00\n",
      "\n",
      "At iterate  100    f=  2.93562D+03    |proj g|=  2.97590D+01\n",
      "\n",
      "At iterate  150    f=  2.58232D+03    |proj g|=  6.47243D+00\n",
      "\n",
      "At iterate  150    f=  2.63085D+03    |proj g|=  8.23271D+00\n",
      "\n",
      "At iterate  150    f=  2.85698D+03    |proj g|=  1.94743D+01\n",
      "\n",
      "At iterate  200    f=  2.49230D+03    |proj g|=  2.73680D+00\n",
      "\n",
      "At iterate  200    f=  2.54261D+03    |proj g|=  7.55089D+00\n",
      "\n",
      "At iterate  200    f=  2.75476D+03    |proj g|=  7.58335D+00\n",
      "\n",
      "At iterate  250    f=  2.43205D+03    |proj g|=  2.02629D+00\n",
      "\n",
      "At iterate  250    f=  2.47537D+03    |proj g|=  2.57958D+00\n",
      "\n",
      "At iterate  250    f=  2.65589D+03    |proj g|=  4.58363D+00\n",
      "\n",
      "At iterate  300    f=  2.43945D+03    |proj g|=  6.95040D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    320      1     0     0   6.950D+00   2.439D+03\n",
      "  F =   2439.4522833734582     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  300    f=  2.39858D+03    |proj g|=  2.16705D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    335      1     0     0   2.167D+00   2.399D+03\n",
      "  F =   2398.5783711407707     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n",
      "\n",
      "At iterate  300    f=  2.60339D+03    |proj g|=  2.96221D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "52460    300    326      1     0     0   2.962D+00   2.603D+03\n",
      "  F =   2603.3918599752178     \n",
      "\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   25.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.68\n",
      "Accuracy: 0.79\n",
      "Auc: 0.98\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.76      0.54      0.63       147\n",
      "     british       0.66      0.48      0.56       242\n",
      "cajun_creole       0.78      0.67      0.72       495\n",
      "     chinese       0.78      0.86      0.81       760\n",
      "    filipino       0.71      0.59      0.64       200\n",
      "      french       0.61      0.64      0.63       820\n",
      "       greek       0.79      0.71      0.75       354\n",
      "      indian       0.88      0.91      0.89       899\n",
      "       irish       0.63      0.48      0.54       207\n",
      "     italian       0.81      0.90      0.85      2351\n",
      "    jamaican       0.89      0.67      0.76       135\n",
      "    japanese       0.83      0.70      0.76       443\n",
      "      korean       0.84      0.75      0.79       249\n",
      "     mexican       0.91      0.92      0.92      1957\n",
      "    moroccan       0.83      0.74      0.78       237\n",
      "     russian       0.55      0.43      0.48       144\n",
      " southern_us       0.70      0.79      0.74      1289\n",
      "     spanish       0.61      0.50      0.55       282\n",
      "        thai       0.80      0.77      0.79       484\n",
      "  vietnamese       0.72      0.56      0.63       238\n",
      "\n",
      "    accuracy                           0.79     11933\n",
      "   macro avg       0.75      0.68      0.71     11933\n",
      "weighted avg       0.79      0.79      0.78     11933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "create_model_cuisine_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64f09199",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_embeddings(data): # Recipe dataset\n",
    "    data = data['ingredients_query'].tolist()\n",
    "    tagged_data = [TaggedDocument(words=row.split(), tags=[str(index)]) for index, row in enumerate(data)]\n",
    "\n",
    "    # hyperparmeters (tune later?)\n",
    "    max_epochs = 20\n",
    "    vec_size = 50\n",
    "    alpha = 0.025\n",
    "\n",
    "    model_embedding = Doc2Vec(vector_size=vec_size,\n",
    "                        alpha=alpha, \n",
    "                        min_alpha=0.00025,\n",
    "                        min_count=1,\n",
    "                        dm =1)\n",
    "  \n",
    "    model_embedding.build_vocab(tagged_data)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "        model_embedding.train(tagged_data,\n",
    "                    total_examples=model_embedding.corpus_count,\n",
    "                    epochs=model_embedding.epochs)\n",
    "        # decrease the learning rate\n",
    "        model_embedding.alpha -= 0.0002\n",
    "        # fix the learning rate, no decay\n",
    "        model_embedding.min_alpha = model_embedding.alpha\n",
    "    \n",
    "    return model_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b943f8",
   "metadata": {},
   "source": [
    "recipes-telegram-bot/src/data_base/generate_db.py /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac266f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to move this chunck down \n",
    "# Database Part I\n",
    "\n",
    "import sqlite3 as sq\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#from src.recommendation_engine.data import import_recipes_main\n",
    "#from src.recommendation_engine.feature_engineering import process_recipes\n",
    "#from src.recommendation_engine.inference import load_pkl\n",
    "\n",
    "MODEL_PATH = 'models/nlp'\n",
    "\n",
    "def create_and_populate_db():\n",
    "    data = import_recipes_main_test()\n",
    "    \n",
    "    # Process the data\n",
    "    data = process_recipes(data)\n",
    "    \n",
    "    # Predict cuisine from trained model\n",
    "    model = load_pkl(os.path.join(MODEL_PATH, 'pickle_model.pkl'))\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"].tolist())\n",
    "    \n",
    "    db = sq.connect('recipes.db')\n",
    "    #Verify dtypes\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype('str')\n",
    "\n",
    "    print(' ------------------ Check data before populating the db ------------------')\n",
    "    print(data.columns)\n",
    "    print(data.head())\n",
    "    print(data.shape)\n",
    "    data.to_sql('main_recipes', db, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ade73107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Part II\n",
    "\n",
    "import sqlite3 as sq\n",
    "import pandas as pd\n",
    "\n",
    "def get_df_from_db(cuisine):\n",
    "    db = sq.connect('recipes.db')\n",
    "    sql_query = \"SELECT title, instructions, ingredients, ingredients_query FROM main_recipes WHERE cuisine = ?\"\n",
    "    return pd.read_sql(sql_query, db, params=(cuisine,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "31cead27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------ Check data before populating the db ------------------\n",
      "Index(['title', 'ingredients', 'instructions', 'ingredients_query', 'cuisine'], dtype='object')\n",
      "                               title  \\\n",
      "0  Slow Cooker Chicken and Dumplings   \n",
      "1      Awesome Slow Cooker Pot Roast   \n",
      "2               Brown Sugar Meatloaf   \n",
      "3        Best Chocolate Chip Cookies   \n",
      "4  Homemade Mac and Cheese Casserole   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  ['4 skinless, boneless chicken breast halves A...   \n",
      "1  ['2 (10.75 ounce) cans condensed cream of mush...   \n",
      "2  ['1/2 cup packed brown sugar ADVERTISEMENT', '...   \n",
      "3  ['1 cup butter, softened ADVERTISEMENT', '1 cu...   \n",
      "4  ['8 ounces whole wheat rotini pasta ADVERTISEM...   \n",
      "\n",
      "                                        instructions  \\\n",
      "0  Place the chicken, butter, soup, and onion in ...   \n",
      "1  In a slow cooker, mix cream of mushroom soup, ...   \n",
      "2  Preheat oven to 350 degrees F (175 degrees C)....   \n",
      "3  Preheat oven to 350 degrees F (175 degrees C)....   \n",
      "4  Preheat oven to 350 degrees F. Line a 2-quart ...   \n",
      "\n",
      "                                   ingredients_query      cuisine  \n",
      "0   skinless boneless chicken breast half butter ...  southern_us  \n",
      "1   can condensed cream mushroom soup package dry...      italian  \n",
      "2   packed brown sugar ketchup lean ground beef m...  southern_us  \n",
      "3   butter softened white sugar packed brown suga...  southern_us  \n",
      "4   whole wheat rotini pasta fresh broccoli flore...      italian  \n",
      "(124647, 5)\n"
     ]
    }
   ],
   "source": [
    "create_and_populate_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc817ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_embeddings():\n",
    "    db = sq.connect('recipes.db')\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    for cuisine in CUISINE_CLASSES:\n",
    "        sql_query = \"SELECT title, instructions, ingredients, ingredients_query FROM main_recipes WHERE cuisine = ?\"\n",
    "        data = pd.read_sql(sql_query, db, params=(cuisine,))\n",
    "        \n",
    "        model_embedding = d2v_embeddings(data)\n",
    "        save_pkl(model_embedding, os.path.join(MODEL_EMBEDDINGS_PATH, f'd2v_{cuisine}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d8db847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n"
     ]
    }
   ],
   "source": [
    "train_model_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b95c1e",
   "metadata": {},
   "source": [
    "recipes-telegram-bot/src/recommendation_engine/inference.py /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "MODEL_PATH = 'models/nlp'\n",
    "MODEL_EMBEDDINGS_PATH = os.path.join(MODEL_PATH, 'similarity_embeddings')\n",
    "CUISINE_CLASSES = ['greek','southern_us','filipino','indian','jamaican','spanish','italian','mexican','chinese','british','thai','vietnamese','cajun_creole','brazilian','french','japanese','irish','korean','moroccan','russian']\n",
    "\n",
    "#from src.recommendation_engine.feature_engineering import get_tokenize_text\n",
    "#from src.data_base.inference import get_df_from_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24750ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from file\n",
    "def load_pkl(pkl_filename):\n",
    "    with open(pkl_filename, 'rb') as pkl_file:\n",
    "        return pickle.load(pkl_file)\n",
    "\n",
    "def infer_cuisine_type_on_recipes(data):\n",
    "    model_path = os.path.join(MODEL_PATH, 'pickle_model.pkl')\n",
    "    model = load_pkl(model_path)\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"])\n",
    "    return data\n",
    "    \n",
    "def predict_cuisine(input_text):\n",
    "    top = 5\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text)\n",
    "    \n",
    "    # Get model\n",
    "    model_path = os.path.join(MODEL_PATH, 'pickle_model.pkl')\n",
    "    model = load_pkl(model_path)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text)\n",
    "\n",
    "    # Get classes ordered by probability\n",
    "    proba = model.predict_proba([tokenize_text])[0]\n",
    "\n",
    "    # Sorted index list \n",
    "    indexes = sorted(range(len(proba)), key=lambda k: proba[k], reverse=True)\n",
    "\n",
    "    # Get cuisine\n",
    "    cuisine_labels = model.classes_.tolist()\n",
    "    cusine_ordered = [cuisine_labels[ind] for ind in indexes]\n",
    "\n",
    "    return cusine_ordered[:top]\n",
    "\n",
    "def get_similar_recipes(input_text, cuisine, top_k=3):\n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text).split()\n",
    "    \n",
    "    # Load model from the selected cuisine\n",
    "    d2v = load_pkl(os.path.join(MODEL_EMBEDDINGS_PATH, f'd2v_{cuisine}.pkl'))\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = d2v.infer_vector(tokenize_text)\n",
    "    best_recipes = d2v.docvecs.most_similar([embeddings]) #gives you top 10 document tags and their cosine similarity\n",
    "\n",
    "    # Get recipes\n",
    "    best_recipes_index = [int(output[0]) for output in best_recipes]\n",
    "    \n",
    "    # Get dDtaFrame\n",
    "    df = get_df_from_db(cuisine)\n",
    "    \n",
    "    return df[df.index.isin(best_recipes_index)].head(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91f7dc4",
   "metadata": {},
   "source": [
    "recipes-telegram-bot/src/data_base/inference.py /"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4f4446",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import argparse\n",
    "import logging\n",
    "from typing import Dict\n",
    "\n",
    "from telegram import ReplyKeyboardMarkup, Update, InlineKeyboardMarkup, InlineKeyboardButton\n",
    "from telegram.ext import (\n",
    "    Updater,\n",
    "    CommandHandler,\n",
    "    MessageHandler,\n",
    "    Filters,\n",
    "    ConversationHandler,\n",
    "    CallbackContext,\n",
    "    CallbackQueryHandler,\n",
    ")\n",
    "\n",
    "from src.recommendation_engine.inference import predict_cuisine, get_similar_recipes\n",
    "from src.recognition_engine.inference import classify_image\n",
    "\n",
    "# Create the parser\n",
    "my_parser = argparse.ArgumentParser(description='Give your personal token')\n",
    "\n",
    "# Add the arguments\n",
    "my_parser.add_argument('token', metavar='token', type=str, help='The token given by Fatherbot')\n",
    "\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    #filename= 'telgramBot.log',\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Main interactions\n",
    "CHOOSING, GET_TEXT, GET_IMAGE = range(3)\n",
    "# Callback data\n",
    "CALLBACK1, CALLBACK2 = range(3,5)\n",
    "\n",
    "reply_keyboard = [\n",
    "    ['Show ingredients', 'Get recipes'],\n",
    "    ['Remove item', 'Done'],\n",
    "]\n",
    "markup = ReplyKeyboardMarkup(reply_keyboard, one_time_keyboard=False)\n",
    "\n",
    "def start(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: Start\")\n",
    "\n",
    "    context.user_data['chat_id'] = update.message.chat_id\n",
    "\n",
    "    update.message.reply_text(\n",
    "        \"Hi! I am you recipe bot. What ingredients do you currently have?\"\n",
    "        \"You can send an image or add ingredients by typing it in one or two words\",\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n",
    "\n",
    "def get_basket_txt(list_ingredients):\n",
    "    txt = 'Here are your current ingredients:\\n'\n",
    "    for ingredient in list_ingredients:\n",
    "        txt += f'   - {ingredient}\\n'\n",
    "    return txt\n",
    "\n",
    "def received_image_information(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    photo_file = update.message.photo[-1].get_file()\n",
    "    photo_file.download('infer_image.png')\n",
    "    logger.info(\"Photo of %s: %s\", user.first_name, 'infer_image.jpg')\n",
    "    update.message.reply_text(\n",
    "        'Thanks the photo is being processed'\n",
    "    )\n",
    "\n",
    "    user_data = context.user_data\n",
    "    \n",
    "    # Infer image prediction\n",
    "    ingredient = classify_image('infer_image.png')\n",
    "    \n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(ingredient[0], callback_data=ingredient[0]),\n",
    "            InlineKeyboardButton(ingredient[1], callback_data=ingredient[1]),\n",
    "            InlineKeyboardButton(ingredient[2], callback_data=ingredient[2])],\n",
    "        [\n",
    "            InlineKeyboardButton(ingredient[3], callback_data=ingredient[3]),\n",
    "            InlineKeyboardButton(ingredient[4], callback_data=ingredient[4]),\n",
    "        ]\n",
    "    ]\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    # Send message with text and appended InlineKeyboard\n",
    "    update.message.reply_text(\"Chose the ingredients you have on your image!\", reply_markup=reply_markup)\n",
    "\n",
    "    return CALLBACK1\n",
    "\n",
    "def button1(update: Update, context: CallbackContext) -> int:\n",
    "    logger.info(f\": button1\")\n",
    "\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "\n",
    "    user_data = context.user_data    \n",
    "    if 'ingredients_list' not in user_data:\n",
    "        user_data['ingredients_list'] = [query.data]\n",
    "    else:\n",
    "        user_data['ingredients_list'].append(query.data)\n",
    "\n",
    "    query.edit_message_text(text=f\"Ok you selected: {query.data}\")\n",
    "    \n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    context.bot.send_message(chat_id=context.user_data['chat_id'], text=txt)\n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "def recipes_query(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\" Get recipes \"\"\"\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: recipes_query\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "\n",
    "    input_text = ' '.join(user_data['ingredients_list'])\n",
    "\n",
    "    # Predict cuisine\n",
    "    cuisine = predict_cuisine(input_text)\n",
    "\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(cuisine[0], callback_data=cuisine[0]),\n",
    "            InlineKeyboardButton(cuisine[1], callback_data=cuisine[1]),\n",
    "            InlineKeyboardButton(cuisine[2], callback_data=cuisine[2])],\n",
    "        [\n",
    "            InlineKeyboardButton(cuisine[3], callback_data=cuisine[3]),\n",
    "            InlineKeyboardButton(cuisine[4], callback_data=cuisine[4]),\n",
    "        ]\n",
    "    ]\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    # Send message with text and appended InlineKeyboard\n",
    "    update.message.reply_text(\"Chose the type of cuisine you want!\", reply_markup=reply_markup)\n",
    "\n",
    "    return CALLBACK2\n",
    "\n",
    "def button2(update: Update, context: CallbackContext) -> int:\n",
    "    #user = update.message.from_user\n",
    "    logger.info(f\"button2\")\n",
    "\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "\n",
    "    # Get recipes\n",
    "    recipes = get_similar_recipes(context.user_data['ingredients_list'], query.data)\n",
    "\n",
    "    sep = '\\n\\n'\n",
    "    for index, row in recipes.iterrows():\n",
    "\n",
    "        title = 'Title: ' + row['title'] \n",
    "        ingredients=''\n",
    "        list_ing = row['ingredients'].replace('ADVERTISEMENT', '').strip('][').split(', ')\n",
    "        for ingredient in list_ing:\n",
    "            ingredients+= ingredient.replace(\"'\", \"\") + '\\n'\n",
    "        ingredients = 'Ingredients: ' + '\\n' + ingredients\n",
    "        instructions = 'Instruction: '+ '\\n' + row['instructions']\n",
    "\n",
    "        txt = title + sep + ingredients + sep + instructions\n",
    "\n",
    "        context.bot.send_message(chat_id=context.user_data['chat_id'], text=txt)\n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "def show_basket(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: show_basket\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    \n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    \n",
    "    update.message.reply_text(\n",
    "        txt,\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n",
    "\n",
    "def received_text_information(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: received_text_information\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    text = update.message.text\n",
    "    \n",
    "    if 'ingredients_list' not in user_data:\n",
    "        user_data['ingredients_list'] = [text]\n",
    "    else:\n",
    "        user_data['ingredients_list'].append(text)\n",
    "\n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    update.message.reply_text(\n",
    "        txt,\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n",
    "\n",
    "def remove_item(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: remove_item\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    if 'ingredients_list' in user_data:\n",
    "        del user_data['ingredients_list'][-1]\n",
    "    \n",
    "    introduction = 'You have deleted the last ingredient. '\n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    update.message.reply_text(\n",
    "        introduction + txt,\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n",
    "\n",
    "def done(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: done\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    if 'ingredients_list' in user_data:\n",
    "        del user_data['ingredients_list']\n",
    "\n",
    "    update.message.reply_text(\n",
    "        f\"Bye bye until next time!\"\n",
    "    )\n",
    "\n",
    "    user_data.clear()\n",
    "    return ConversationHandler.END    \n",
    "\n",
    "def main(bot_token) -> None:\n",
    "    # Create the Updater and pass it your bot's token.\n",
    "    # Make sure to set use_context=True to use the new context based callbacks\n",
    "    # Post version 12 this will no longer be necessary\n",
    "    updater = Updater(bot_token, use_context=True)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Add conversation handler with the states CHOOSING, TYPING_CHOICE and TYPING_REPLY\n",
    "    conv_handler = ConversationHandler(\n",
    "        entry_points=[CommandHandler('start', start)],\n",
    "        states={\n",
    "            CHOOSING: [\n",
    "                MessageHandler(Filters.photo & ~(Filters.command | Filters.regex('^(Done|Get recipes|Show ingredients|Remove item)$')), received_image_information),\n",
    "                MessageHandler(Filters.text & ~(Filters.command | Filters.regex('^(Done|Get recipes|Show ingredients|Remove item)$')), received_text_information),\n",
    "                MessageHandler(Filters.regex('^Get recipes$'), recipes_query),\n",
    "                MessageHandler(Filters.regex('^Show ingredients$'), show_basket),\n",
    "                MessageHandler(Filters.regex('^Remove item$'), remove_item),\n",
    "            ],\n",
    "            CALLBACK1: [\n",
    "                CallbackQueryHandler(button1)],\n",
    "            CALLBACK2: [\n",
    "                CallbackQueryHandler(button2)],\n",
    "        },\n",
    "        fallbacks=[MessageHandler(Filters.regex('^Done$'), done)],\n",
    "        per_message=False,\n",
    "    )\n",
    "\n",
    "    dispatcher.add_handler(conv_handler)\n",
    "\n",
    "    # Start the Bot\n",
    "    updater.start_polling()\n",
    "\n",
    "    # Run the bot until you press Ctrl-C or the process receives SIGINT,\n",
    "    # SIGTERM or SIGABRT. This should be used most of the time, since\n",
    "    # start_polling() is non-blocking and will stop the bot gracefully.\n",
    "    updater.idle()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Execute the parse_args() method\n",
    "    args = my_parser.parse_args()\n",
    "    main(args.token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
