{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Recipe Chatbot Project</center></h1>\n",
    "<h2><center>DATA-641</center></h2>\n",
    "<h3><center>Sobanaa Jayakumar & Reina Villanueva-Unger</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "### A. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsoba\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "#feature engg\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#model & processing libraries\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "from sklearn import feature_selection\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn import utils\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#Sampling \n",
    "from imblearn import pipeline as pl\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Embeddings\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "#DB accesses\n",
    "import sqlite3 as sq\n",
    "\n",
    "#to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import libraries for chatbot\n",
    "import argparse\n",
    "import logging\n",
    "from typing import Dict\n",
    "\n",
    "from telegram import ReplyKeyboardMarkup, Update, InlineKeyboardMarkup, InlineKeyboardButton\n",
    "from telegram.ext import (Updater, CommandHandler, MessageHandler, Filters, ConversationHandler, CallbackContext, CallbackQueryHandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Set Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_path = \"data/cuisine_data/\"\n",
    "recipes_path = \"data/recipes_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Model Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/nlp\"\n",
    "model_embeddings_path = os.path.join(model_path, 'similarity_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuisine data\n",
    "def import_cuisine_data(): \n",
    "    train = pd.read_json(os.path.join(cuisine_path, 'train.json'))\n",
    "    return train\n",
    "\n",
    "#Recipe Data \n",
    "def import_recipe_data():\n",
    "    all_recipes = pd.read_json('./data/recipes_data/recipes_raw_nosource_allrecipes.json', orient='index')\n",
    "    epicurious = pd.read_json('./data/recipes_data/recipes_raw_nosource_epicurious.json', orient='index')\n",
    "    food_network = pd.read_json('./data/recipes_data/recipes_raw_nosource_foodnetwork.json', orient='index')\n",
    "    data = pd.concat([all_recipes, epicurious, food_network], axis=0)\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    data = data.drop(columns=['index', 'picture_link'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Set Cuisine Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_classes = ['greek','southern_us','filipino','indian','jamaican','spanish','italian','mexican','chinese','british','thai','vietnamese','cajun_creole','brazilian','french','japanese','irish','korean','moroccan','russian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stop_words = [\"advertisement\", \"advertisements\",\n",
    "                         \"cup\", \"cups\",\n",
    "                         \"tablespoon\", \"tablespoons\", \n",
    "                         \"teaspoon\", \"teaspoons\", \n",
    "                         \"ounce\", \"ounces\",\n",
    "                         \"salt\", \n",
    "                         \"pepper\", \n",
    "                         \"pound\", \"pounds\",\n",
    "                         ]\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list.extend(additional_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. String Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. String Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def clean_text(list, lemmatize = True, stemming = False, lst_stopwords=None):\n",
    "    str = ' '.join(list) #converting the list to string\n",
    "    clean_text = ''\n",
    "    \n",
    "    lower = str.lower().split() #lowercase and tokenize\n",
    "    \n",
    "    lst_text = []\n",
    "    clean_words = []\n",
    "    for word in lower:\n",
    "        if len(word) > 2:\n",
    "            digit = re.sub(r'\\d+','', word) #removing digits\n",
    "            text = re.sub(r'[^\\w\\s]', '', digit) #removing punc and characters\n",
    "            \n",
    "            \n",
    "            if lemmatize:\n",
    "                lm = WordNetLemmatizer()  #lemmatize\n",
    "                lemm = lm.lemmatize(text)\n",
    "                clean_words.append(lemm)\n",
    "                \n",
    "                if stemming:\n",
    "                    stemmer = PorterStemmer #stemming\n",
    "                    stemm = stemmer.stem(text)\n",
    "                    clean_words.append(stemm)\n",
    "         \n",
    "    #if lst_stopwords is not None:\n",
    "        #lst_text = [word for word in lst_text if word not in \n",
    "                    #lst_stopwords] #remove stopwords\n",
    "    \n",
    "    clean_text = ' '.join(lst_text) #join as a string\n",
    "    text = re.sub(' +', ' ', clean_text) #remove multi-spaces\n",
    "    \n",
    "    return text  \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def process_cuisine(): # !!!--- NEED TO UPDATE LATER IN CODE ---!!! originally: process_data()\n",
    "    cuisine_data = import_cuisine_data() # cuisine\n",
    "\n",
    "    def processing(row):\n",
    "        ls = row['ingredients']\n",
    "        return ' '.join(ls)\n",
    "\n",
    "    cuisine_data['ingredients'] = cuisine_data.apply(lambda x: processing(x), axis=1)\n",
    "    cuisine_data.dropna(inplace=True)\n",
    "    cuisine_data = cuisine_data.drop(columns=['id']).reset_index(drop=True)\n",
    "\n",
    "    cuisine_data[\"ingredients_query\"] = cuisine_data[\"ingredients\"].apply(lambda x: \n",
    "          clean_text(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return cuisine_data\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def process_recipes(data): # Recipes dataset\n",
    "    data[\"ingredients_query\"] = data[\"ingredients\"].apply(lambda x: \n",
    "            clean_text(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return data\n",
    "\n",
    "def get_tokenize_text(input_text):\n",
    "    return clean_text(iclean_textnput_text, stemming=False, lemmatize=True, lst_stopwords=stopword_list)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cuisine_data = process_cuisine()\n",
    "X = cuisine_data['ingredients_query']\n",
    "y = cuisine_data['cuisine']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def create_model_cuisine_predictions():\n",
    "    # Classifer\n",
    "    classifier = LogisticRegression(random_state=123,\n",
    "                                      max_iter=300,\n",
    "                                      n_jobs=-1,\n",
    "                                      multi_class = 'multinomial', \n",
    "                                      solver = 'lbfgs', \n",
    "                                      C = 10, \n",
    "                                      penalty = 'l2',\n",
    "                                      verbose=1\n",
    "                                      ) \n",
    "    ## pipeline\n",
    "    model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                                (\"classifier\", classifier)])\n",
    "\n",
    "    #Fitting Vectorizer\n",
    "    #matrix_train_lr = vectorizer.fit_transform(X_train)\n",
    "    #matrix_test_lr = vectorizer.transform(X_test)\n",
    "\n",
    "    # Fit Model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_train)\n",
    "\n",
    "    # Save as Pkl\n",
    "    save_pkl(model, os.path.join(model_path, \"pickle_model.pkl\"))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model_path = 'models/nlp'\n",
    "\n",
    "def create_and_populate_db():\n",
    "    data = import_recipe_data()\n",
    "    \n",
    "    # Process the data\n",
    "    data = process_recipes(data)\n",
    "    \n",
    "    # Predict cuisine from trained model\n",
    "    model = load_pkl(os.path.join(model_path, 'pickle_model.pkl'))\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"].tolist())  #this is predicting cuisine for recipe dataset\n",
    "    \n",
    "    db = sq.connect('recipes.db')\n",
    "    #Verify dtypes\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype('str')\n",
    "\n",
    "    print(' ------------------ Check data before populating the db ------------------')\n",
    "    print(data.columns)\n",
    "    print(data.head())\n",
    "    print(data.shape)\n",
    "    data.to_sql('main_recipes', db, if_exists='replace')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing function - From the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this function!!!\n",
    "def clean_string(text, stemming=False, lemmatize=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "     \n",
    "    lst_text = []    \n",
    "    ## Tokenize (convert from string to list)\n",
    "    if len(text) > 2:\n",
    "        lst_text = text.split()\n",
    "\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if stemming == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if lemmatize == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "\n",
    "    ## Remove digits\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    ## remove mutliple space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Preprocess Cuisine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cuisine(): # !!!--- NEED TO UPDATE LATER IN CODE ---!!! originally: process_data()\n",
    "    cuisine_data = import_cuisine_data() # cuisine\n",
    "\n",
    "    def processing(row):\n",
    "        ls = row['ingredients']\n",
    "        return ' '.join(ls)\n",
    "\n",
    "    cuisine_data['ingredients'] = cuisine_data.apply(lambda x: processing(x), axis=1)\n",
    "    cuisine_data.dropna(inplace=True)\n",
    "    cuisine_data = cuisine_data.drop(columns=['id']).reset_index(drop=True)\n",
    "\n",
    "    cuisine_data[\"ingredients_query\"] = cuisine_data[\"ingredients\"].apply(lambda x: \n",
    "          clean_string(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return cuisine_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Preprocess Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recipes(data): # Recipes dataset\n",
    "    data[\"ingredients_query\"] = data[\"ingredients\"].apply(lambda x: \n",
    "            clean_string(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return data\n",
    "\n",
    "def get_tokenize_text(input_text):\n",
    "    return clean_string(input_text, stemming=False, lemmatize=True, lst_stopwords=stopword_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Defining variables - Cuisine subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_subset = process_cuisine().sample(n = 17000)\n",
    "X_s = cuisine_subset['ingredients_query']\n",
    "y_s = cuisine_subset['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Defining variables - Cuisine full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_data = process_cuisine()\n",
    "X = cuisine_data['ingredients_query']\n",
    "y = cuisine_data['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cuisine Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Defining vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Defining Test_train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Tested Multiple Categorization Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.a. Logistic Regression - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 500, random_state = 123, multi_class = 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 10\n",
      "Best Solver: lbfgs\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "penalty = ['l2', 'l1', 'elasticnet']\n",
    "C = [0.001, 0.01, 0.1, 10]\n",
    "solvers = ['newton-cg', 'lbfgs']\n",
    "\n",
    "#Fitting into pipeline\n",
    "lr_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('lr', lr)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(lr__C = C, lr__penalty = penalty, lr__solver = solvers)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(lr_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['lr__penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['lr__C'])\n",
    "print('Best Solver:', best_model.best_estimator_.get_params()['lr__solver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.b. Logistic Regression - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7835600708811891\n",
      "Accuracy score 0.7874094931617055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.80      0.57      0.67       117\n",
      "     british       0.61      0.45      0.52       201\n",
      "cajun_creole       0.78      0.69      0.73       386\n",
      "     chinese       0.81      0.87      0.84       668\n",
      "    filipino       0.79      0.57      0.66       189\n",
      "      french       0.58      0.67      0.62       662\n",
      "       greek       0.77      0.69      0.72       294\n",
      "      indian       0.87      0.91      0.89       751\n",
      "       irish       0.69      0.49      0.57       167\n",
      "     italian       0.81      0.89      0.84      1960\n",
      "    jamaican       0.92      0.71      0.80       131\n",
      "    japanese       0.85      0.69      0.76       356\n",
      "      korean       0.86      0.75      0.80       207\n",
      "     mexican       0.91      0.91      0.91      1610\n",
      "    moroccan       0.81      0.77      0.79       205\n",
      "     russian       0.65      0.45      0.53       122\n",
      " southern_us       0.72      0.81      0.76      1080\n",
      "     spanish       0.61      0.47      0.53       247\n",
      "        thai       0.74      0.81      0.77       385\n",
      "  vietnamese       0.68      0.48      0.56       206\n",
      "\n",
      "    accuracy                           0.79      9944\n",
      "   macro avg       0.76      0.68      0.71      9944\n",
      "weighted avg       0.79      0.79      0.78      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train_lr = vectorizer.fit_transform(X_train)\n",
    "matrix_test_lr = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "lr_final = LogisticRegression(max_iter = 300, random_state = 123, multi_class ='multinomial', solver = 'lbfgs', C = 10, penalty = 'l2')\n",
    "lr_final.fit(matrix_train_lr, y_train)\n",
    "y_pred = lr_final.predict(matrix_test_lr)\n",
    "pred_prob = lr_final.predict_proba(matrix_test_lr)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, pred_prob))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#cm_lr_test=confusion_matrix(y_test, y_pred)\n",
    "#print(cm_lr_test)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred)\n",
    "f1_lr = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ii.a. Multinomial Naive Bayes - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.01\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params\n",
    "alpha = [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "\n",
    "#Fitting into pipeline\n",
    "nb_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('nb', nb)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(nb__alpha = alpha)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(nb_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Alpha:', best_model.best_estimator_.get_params()['nb__alpha'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.b. Multinomial Naive Bayes - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.736116043309851\n",
      "Accuracy score 0.7412510056315366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.71      0.47      0.57       117\n",
      "     british       0.52      0.41      0.46       201\n",
      "cajun_creole       0.66      0.69      0.68       386\n",
      "     chinese       0.76      0.88      0.81       668\n",
      "    filipino       0.81      0.49      0.61       189\n",
      "      french       0.52      0.60      0.56       662\n",
      "       greek       0.74      0.56      0.64       294\n",
      "      indian       0.84      0.87      0.86       751\n",
      "       irish       0.71      0.44      0.54       167\n",
      "     italian       0.78      0.85      0.81      1960\n",
      "    jamaican       0.85      0.58      0.69       131\n",
      "    japanese       0.85      0.64      0.73       356\n",
      "      korean       0.88      0.65      0.75       207\n",
      "     mexican       0.88      0.88      0.88      1610\n",
      "    moroccan       0.76      0.70      0.73       205\n",
      "     russian       0.66      0.34      0.45       122\n",
      " southern_us       0.63      0.75      0.68      1080\n",
      "     spanish       0.58      0.37      0.45       247\n",
      "        thai       0.66      0.78      0.71       385\n",
      "  vietnamese       0.63      0.43      0.51       206\n",
      "\n",
      "    accuracy                           0.74      9944\n",
      "   macro avg       0.72      0.62      0.66      9944\n",
      "weighted avg       0.74      0.74      0.74      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb_final = MultinomialNB(alpha = 0.01)\n",
    "nb_final.fit(matrix_train, y_train)\n",
    "y_pred = nb_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average ='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_mnb = accuracy_score(y_test, y_pred)\n",
    "f1_mnb = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.a. Random Forest - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: 500\n",
      "Best features: sqrt\n",
      "Best samples split: 2\n",
      "Best samples leaf: 5\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "n_estimators = [10, 100, 500]\n",
    "max_features = ['sqrt', 'log2']\n",
    "min_samples_split = [2, 10, 100]\n",
    "min_samples_leaf = [5, 10] \n",
    "\n",
    "\n",
    "#Fitting into pipeline\n",
    "rf_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('rf', rf)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(rf__n_estimators = estimators, rf__max_features = max_features, rf__min_samples_split = min_samples_split, rf__min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(rf_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Estimator:', best_model.best_estimator_.get_params()['rf__n_estimators'])\n",
    "print('Best features:', best_model.best_estimator_.get_params()['rf__max_features'])\n",
    "print('Best samples split:', best_model.best_estimator_.get_params()['rf__min_samples_split'])\n",
    "print('Best samples leaf:', best_model.best_estimator_.get_params()['rf__min_samples_leaf'])\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.b. Random Forest - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.5706338276541044\n",
      "Accuracy score 0.6288213998390989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.85      0.24      0.37       117\n",
      "     british       1.00      0.00      0.01       201\n",
      "cajun_creole       0.89      0.49      0.63       386\n",
      "     chinese       0.61      0.90      0.72       668\n",
      "    filipino       1.00      0.07      0.14       189\n",
      "      french       0.58      0.20      0.30       662\n",
      "       greek       0.93      0.23      0.37       294\n",
      "      indian       0.78      0.86      0.82       751\n",
      "       irish       0.80      0.02      0.05       167\n",
      "     italian       0.56      0.92      0.69      1960\n",
      "    jamaican       1.00      0.12      0.22       131\n",
      "    japanese       0.96      0.46      0.62       356\n",
      "      korean       0.98      0.20      0.34       207\n",
      "     mexican       0.73      0.91      0.81      1610\n",
      "    moroccan       0.98      0.21      0.35       205\n",
      "     russian       0.00      0.00      0.00       122\n",
      " southern_us       0.47      0.71      0.56      1080\n",
      "     spanish       0.00      0.00      0.00       247\n",
      "        thai       0.68      0.66      0.67       385\n",
      "  vietnamese       0.76      0.08      0.14       206\n",
      "\n",
      "    accuracy                           0.63      9944\n",
      "   macro avg       0.73      0.36      0.39      9944\n",
      "weighted avg       0.67      0.63      0.57      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train_rf = vectorizer.fit_transform(X_train)\n",
    "matrix_test_rf = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "rf_final = RandomForestClassifier(random_state = 123, n_estimators = 500, max_features = 'sqrt', min_samples_split = 2, min_samples_leaf = 5)\n",
    "rf_final.fit(matrix_train_rf, y_train)\n",
    "y_pred = rf_final.predict(matrix_test_rf)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average ='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred)\n",
    "f1_rf = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.a. SVC - Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Kernel: sigmoid\n",
      "Best C: 10\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "kernel = ['rbf', 'poly', 'sigmoid']  \n",
    "C = [0.001, 0.01, 0.1, 10]\n",
    "\n",
    "#Fitting into pipeline\n",
    "svc_pipe = Pipeline([('vect', vectorizer),\n",
    "                      #('densify', SparseToDense()),\n",
    "                      #('scale', StandardScaler()),\n",
    "                      ('svc', svc)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(svc__kernel = kernel, svc__C = C)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(svc_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X_s, y_s)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Kernel:', best_model.best_estimator_.get_params()['svc__kernel'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['svc__C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.b. SVC - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7521964647011117\n",
      "Accuracy score 0.7526146419951729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.67      0.65      0.66       117\n",
      "     british       0.49      0.53      0.51       201\n",
      "cajun_creole       0.71      0.69      0.70       386\n",
      "     chinese       0.79      0.84      0.81       668\n",
      "    filipino       0.67      0.61      0.64       189\n",
      "      french       0.50      0.64      0.56       662\n",
      "       greek       0.68      0.69      0.68       294\n",
      "      indian       0.85      0.88      0.86       751\n",
      "       irish       0.51      0.47      0.49       167\n",
      "     italian       0.80      0.82      0.81      1960\n",
      "    jamaican       0.85      0.76      0.80       131\n",
      "    japanese       0.76      0.68      0.72       356\n",
      "      korean       0.84      0.74      0.78       207\n",
      "     mexican       0.89      0.89      0.89      1610\n",
      "    moroccan       0.77      0.76      0.77       205\n",
      "     russian       0.57      0.41      0.48       122\n",
      " southern_us       0.73      0.70      0.71      1080\n",
      "     spanish       0.55      0.43      0.49       247\n",
      "        thai       0.76      0.78      0.77       385\n",
      "  vietnamese       0.62      0.50      0.55       206\n",
      "\n",
      "    accuracy                           0.75      9944\n",
      "   macro avg       0.70      0.67      0.68      9944\n",
      "weighted avg       0.75      0.75      0.75      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "svc_final = SVC(random_state = 123, kernel = 'sigmoid', C = 10)\n",
    "svc_final.fit(matrix_train, y_train)\n",
    "y_pred = svc_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred)\n",
    "f1_svm = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v.a. XGB - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBClassifier(objective = 'multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth: 1\n",
      "Best Gamma: 1\n",
      "Best Alpha: 1\n",
      "Best Lambda: 0\n",
      "Best Colsample: 0.5\n",
      "Best Child weight: 1\n",
      "Best ETA: 0.5\n"
     ]
    }
   ],
   "source": [
    "max_depth = [1, 5, 20, 50]\n",
    "gamma = [1, 10]\n",
    "reg_alpha = [1, 40, 180]\n",
    "reg_lambda = [0, 1]\n",
    "colsample_bytree = [0.5, 1]\n",
    "min_child_weight = [0, 1, 10]\n",
    "eta = [0.5, 1]\n",
    "\n",
    "\n",
    "xgb_pipe = Pipeline([('vect', vectorizer),\n",
    "                      ('xgb', xgb)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(xgb__max_depth = max_depth, xgb__gamma = gamma, xgb__reg_alpha = reg_alpha, \n",
    "                       xgb__reg_lambda = reg_lambda, xgb__colsample_bytree = colsample_bytree, xgb__min_child_weight = min_child_weight, xgb__eta = eta)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(xgb_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X_s, y_s)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Depth:', best_model.best_estimator_.get_params()['xgb__max_depth'])\n",
    "print('Best Gamma:', best_model.best_estimator_.get_params()['xgb__gamma'])\n",
    "print('Best Alpha:', best_model.best_estimator_.get_params()['xgb__reg_alpha'])\n",
    "print('Best Lambda:', best_model.best_estimator_.get_params()['xgb__reg_lambda'])\n",
    "print('Best Colsample:', best_model.best_estimator_.get_params()['xgb__colsample_bytree'])\n",
    "print('Best Child weight:', best_model.best_estimator_.get_params()['xgb__min_child_weight'])\n",
    "print('Best ETA:', best_model.best_estimator_.get_params()['xgb__eta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v.b. XGB - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7377902089531876\n",
      "Accuracy score 0.7453740949316171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.78      0.53      0.63       117\n",
      "     british       0.50      0.24      0.33       201\n",
      "cajun_creole       0.79      0.67      0.73       386\n",
      "     chinese       0.78      0.84      0.81       668\n",
      "    filipino       0.68      0.48      0.57       189\n",
      "      french       0.54      0.55      0.54       662\n",
      "       greek       0.81      0.70      0.75       294\n",
      "      indian       0.86      0.86      0.86       751\n",
      "       irish       0.62      0.43      0.50       167\n",
      "     italian       0.70      0.88      0.78      1960\n",
      "    jamaican       0.89      0.67      0.77       131\n",
      "    japanese       0.85      0.65      0.73       356\n",
      "      korean       0.79      0.66      0.72       207\n",
      "     mexican       0.88      0.89      0.89      1610\n",
      "    moroccan       0.81      0.71      0.76       205\n",
      "     russian       0.58      0.34      0.43       122\n",
      " southern_us       0.66      0.76      0.70      1080\n",
      "     spanish       0.63      0.35      0.45       247\n",
      "        thai       0.75      0.79      0.77       385\n",
      "  vietnamese       0.68      0.43      0.53       206\n",
      "\n",
      "    accuracy                           0.75      9944\n",
      "   macro avg       0.73      0.62      0.66      9944\n",
      "weighted avg       0.74      0.75      0.74      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params. Import xgb before running this\n",
    "xgb_final = xgb.XGBClassifier(objective = 'multi:softmax', max_depth = 1, gamma = 1, reg_alpha = 1, \n",
    "                     reg_lambda = 0, colsample_bytree = 0.5, min_child_weight = 1, eta = 0.5, eval_metric = 'mlogloss')\n",
    "\n",
    "xgb_final.fit(matrix_train, y_train)\n",
    "y_pred = xgb_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred)\n",
    "f1_xgb = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi.a. Over and Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_samp = LogisticRegression(max_iter = 300, random_state = 123, multi_class = 'multinomial',  solver = 'newton-cg', C = 10, penalty = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_os = RandomOverSampler(random_state=123)\n",
    "random_us = RandomUnderSampler(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi.b. Oversampling LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on oversampling:\n",
      "\n",
      "f1 score weighted 0.7856498439972385\n",
      "Accuracy score 0.7844931617055511\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   brazilian       0.70      0.68      1.00      0.69      0.82      0.65       117\n",
      "     british       0.53      0.57      0.99      0.55      0.75      0.54       201\n",
      "cajun_creole       0.74      0.75      0.99      0.74      0.86      0.72       386\n",
      "     chinese       0.82      0.85      0.99      0.83      0.91      0.82       668\n",
      "    filipino       0.72      0.65      0.99      0.68      0.80      0.63       189\n",
      "      french       0.58      0.68      0.96      0.62      0.81      0.63       662\n",
      "       greek       0.71      0.77      0.99      0.74      0.87      0.74       294\n",
      "      indian       0.89      0.90      0.99      0.90      0.95      0.89       751\n",
      "       irish       0.57      0.57      0.99      0.57      0.75      0.54       167\n",
      "     italian       0.85      0.83      0.96      0.84      0.89      0.79      1960\n",
      "    jamaican       0.83      0.79      1.00      0.81      0.89      0.78       131\n",
      "    japanese       0.83      0.72      0.99      0.77      0.85      0.70       356\n",
      "      korean       0.81      0.79      1.00      0.80      0.89      0.77       207\n",
      "     mexican       0.93      0.90      0.99      0.91      0.94      0.88      1610\n",
      "    moroccan       0.74      0.81      0.99      0.78      0.90      0.79       205\n",
      "     russian       0.55      0.52      0.99      0.54      0.72      0.50       122\n",
      " southern_us       0.76      0.77      0.97      0.77      0.86      0.73      1080\n",
      "     spanish       0.52      0.52      0.99      0.52      0.72      0.49       247\n",
      "        thai       0.74      0.78      0.99      0.76      0.88      0.76       385\n",
      "  vietnamese       0.62      0.54      0.99      0.58      0.73      0.52       206\n",
      "\n",
      " avg / total       0.79      0.78      0.98      0.79      0.88      0.76      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_os = pl.make_pipeline(vectorizer,\n",
    "                           random_os,\n",
    "                           lr_samp)\n",
    "\n",
    "\n",
    "# Train the classifier with balancing\n",
    "lr_pipe_os.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = lr_pipe_os.predict(X_test)\n",
    "\n",
    "print(\"results on oversampling:\\n\")\n",
    "\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred_bal, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred_bal))\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "\n",
    "acc_os_lr = accuracy_score(y_test, y_pred_bal)\n",
    "f1_os_lr = f1_score(y_test, y_pred_bal, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi.c. Undersampling LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on Undersampling:\n",
      "\n",
      "f1 score weighted 0.7209825708033166\n",
      "Accuracy score 0.7059533386967015\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   brazilian       0.41      0.76      0.99      0.54      0.87      0.73       117\n",
      "     british       0.31      0.61      0.97      0.41      0.77      0.57       201\n",
      "cajun_creole       0.63      0.76      0.98      0.69      0.86      0.73       386\n",
      "     chinese       0.85      0.77      0.99      0.81      0.87      0.75       668\n",
      "    filipino       0.49      0.68      0.99      0.57      0.82      0.65       189\n",
      "      french       0.51      0.54      0.96      0.52      0.72      0.49       662\n",
      "       greek       0.60      0.79      0.98      0.68      0.88      0.76       294\n",
      "      indian       0.91      0.83      0.99      0.87      0.91      0.81       751\n",
      "       irish       0.35      0.63      0.98      0.45      0.79      0.59       167\n",
      "     italian       0.89      0.67      0.98      0.76      0.81      0.63      1960\n",
      "    jamaican       0.62      0.83      0.99      0.71      0.91      0.81       131\n",
      "    japanese       0.80      0.67      0.99      0.73      0.82      0.65       356\n",
      "      korean       0.70      0.77      0.99      0.74      0.88      0.75       207\n",
      "     mexican       0.95      0.81      0.99      0.87      0.90      0.79      1610\n",
      "    moroccan       0.60      0.84      0.99      0.70      0.91      0.82       205\n",
      "     russian       0.33      0.67      0.98      0.44      0.81      0.64       122\n",
      " southern_us       0.79      0.58      0.98      0.67      0.75      0.55      1080\n",
      "     spanish       0.34      0.60      0.97      0.43      0.76      0.56       247\n",
      "        thai       0.75      0.73      0.99      0.74      0.85      0.70       385\n",
      "  vietnamese       0.53      0.64      0.99      0.58      0.79      0.61       206\n",
      "\n",
      " avg / total       0.76      0.71      0.98      0.72      0.83      0.68      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_us = pl.make_pipeline(vectorizer,\n",
    "                           random_us,\n",
    "                           lr_samp)\n",
    "\n",
    "\n",
    "\n",
    "# Train the classifier with balancing\n",
    "lr_pipe_us.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = lr_pipe_us.predict(X_test)\n",
    "\n",
    "print(\"results on Undersampling:\\n\")\n",
    "\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred_bal, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred_bal))\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "\n",
    "acc_us_lr = accuracy_score(y_test, y_pred_bal)\n",
    "f1_us_lr = f1_score(y_test, y_pred_bal, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Dataframe with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787409</td>\n",
       "      <td>0.783560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Oversampled</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.785650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.752615</td>\n",
       "      <td>0.752196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XG Boost Model</td>\n",
       "      <td>0.745374</td>\n",
       "      <td>0.737790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.741251</td>\n",
       "      <td>0.736116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression - Undersampled</td>\n",
       "      <td>0.705953</td>\n",
       "      <td>0.720983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.628821</td>\n",
       "      <td>0.570634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy Score  F1 Score\n",
       "0                 Logistic Regression        0.787409  0.783560\n",
       "3   Logistic Regression - Oversampled        0.784493  0.785650\n",
       "1             Support Vector Machines        0.752615  0.752196\n",
       "2                      XG Boost Model        0.745374  0.737790\n",
       "5                         Naive Bayes        0.741251  0.736116\n",
       "4  Logistic Regression - Undersampled        0.705953  0.720983\n",
       "6                       Random Forest        0.628821  0.570634"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machines', 'XG Boost Model', 'Logistic Regression - Oversampled', \n",
    "              'Logistic Regression - Undersampled', 'Naive Bayes', 'Random Forest'],\n",
    "    'Accuracy Score': [acc_lr, acc_svm, acc_xgb, acc_os_lr, acc_us_lr, acc_mnb, acc_rf],\n",
    "    'F1 Score': [f1_lr, f1_svm, f1_xgb, f1_os_lr, f1_us_lr, f1_mnb, f1_rf]})\n",
    "models.sort_values(by = 'Accuracy Score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Fitting Best Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Saving & Loading Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pkl\n",
    "def load_pkl(pkl_filename):\n",
    "    with open(pkl_filename, 'rb') as pkl_file:\n",
    "        return pickle.load(pkl_file)\n",
    "    \n",
    "## Save pkl\n",
    "def save_pkl(file, pkl_filename):\n",
    "    with open(pkl_filename, 'wb') as pkl_file:\n",
    "        pickle.dump(file, pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_cuisine_predictions():\n",
    "    # Classifer\n",
    "    classifier = LogisticRegression(random_state=123,\n",
    "                                      max_iter=300,\n",
    "                                      n_jobs=-1,\n",
    "                                      multi_class = 'multinomial', \n",
    "                                      solver = 'lbfgs', \n",
    "                                      C = 10, \n",
    "                                      penalty = 'l2') \n",
    "    ## pipeline\n",
    "    model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                                (\"classifier\", classifier)])\n",
    "\n",
    "\n",
    "    # Fit Model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_train)\n",
    "\n",
    "    # Save as Pkl\n",
    "    save_pkl(model, os.path.join(model_path, \"pickle_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_model_cuisine_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Creating a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/nlp'\n",
    "\n",
    "def create_and_populate_db():\n",
    "    data = import_recipe_data()\n",
    "    \n",
    "    # Process the data\n",
    "    data = process_recipes(data)\n",
    "    \n",
    "    # Predict cuisine from trained model\n",
    "    model = load_pkl(os.path.join(model_path, 'pickle_model.pkl'))\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"].tolist())  #this is predicting cuisine for recipe dataset\n",
    "    \n",
    "    db = sq.connect('recipes.db')\n",
    "    #Verify dtypes\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype('str')\n",
    "\n",
    "    print(' ------------------ Check data before populating the db ------------------')\n",
    "    print(data.columns)\n",
    "    print(data.head())\n",
    "    print(data.shape)\n",
    "    data.to_sql('main_recipes', db, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------ Check data before populating the db ------------------\n",
      "Index(['title', 'ingredients', 'instructions', 'ingredients_query', 'cuisine'], dtype='object')\n",
      "                               title  \\\n",
      "0  Slow Cooker Chicken and Dumplings   \n",
      "1      Awesome Slow Cooker Pot Roast   \n",
      "2               Brown Sugar Meatloaf   \n",
      "3        Best Chocolate Chip Cookies   \n",
      "4  Homemade Mac and Cheese Casserole   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  ['4 skinless, boneless chicken breast halves A...   \n",
      "1  ['2 (10.75 ounce) cans condensed cream of mush...   \n",
      "2  ['1/2 cup packed brown sugar ADVERTISEMENT', '...   \n",
      "3  ['1 cup butter, softened ADVERTISEMENT', '1 cu...   \n",
      "4  ['8 ounces whole wheat rotini pasta ADVERTISEM...   \n",
      "\n",
      "                                        instructions  \\\n",
      "0  Place the chicken, butter, soup, and onion in ...   \n",
      "1  In a slow cooker, mix cream of mushroom soup, ...   \n",
      "2  Preheat oven to 350 degrees F (175 degrees C)....   \n",
      "3  Preheat oven to 350 degrees F (175 degrees C)....   \n",
      "4  Preheat oven to 350 degrees F. Line a 2-quart ...   \n",
      "\n",
      "                                   ingredients_query      cuisine  \n",
      "0   skinless boneless chicken breast half butter ...  southern_us  \n",
      "1   can condensed cream mushroom soup package dry...  southern_us  \n",
      "2   packed brown sugar ketchup lean ground beef m...  southern_us  \n",
      "3   butter softened white sugar packed brown suga...      italian  \n",
      "4   whole wheat rotini pasta fresh broccoli flore...      italian  \n",
      "(124647, 5)\n"
     ]
    }
   ],
   "source": [
    "create_and_populate_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_db(cuisine):\n",
    "    db = sq.connect('recipes.db')\n",
    "    sql_query = \"SELECT title, instructions, ingredients, ingredients_query FROM main_recipes WHERE cuisine = ?\"\n",
    "    return pd.read_sql(sql_query, db, params = (cuisine, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G. Doc2Vec function for recipe similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_embeddings(data): # Recipe dataset\n",
    "    data = data['ingredients_query'].tolist()\n",
    "    tagged_data = [TaggedDocument(words=row.split(), tags=[str(index)]) for index, row in enumerate(data)]\n",
    "\n",
    "    max_epochs = 20\n",
    "    vec_size = 50\n",
    "    alpha = 0.025\n",
    "\n",
    "    model_embedding = Doc2Vec(vector_size=vec_size,\n",
    "                        alpha=alpha, \n",
    "                        min_alpha=0.00025,\n",
    "                        min_count=1,\n",
    "                        dm =1)\n",
    "  \n",
    "    model_embedding.build_vocab(tagged_data)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "        model_embedding.train(tagged_data,\n",
    "                    total_examples=model_embedding.corpus_count,\n",
    "                    epochs=model_embedding.epochs)\n",
    "        # decrease the learning rate\n",
    "        model_embedding.alpha -= 0.0002\n",
    "        # fix the learning rate, no decay\n",
    "        model_embedding.min_alpha = model_embedding.alpha\n",
    "    \n",
    "    return model_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_embeddings():\n",
    "    db = sq.connect('recipes.db')\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    for cuisine in cuisine_classes:\n",
    "        sql_query = \"SELECT title, instructions, ingredients, ingredients_query FROM main_recipes WHERE cuisine = ?\"\n",
    "        data = pd.read_sql(sql_query, db, params=(cuisine,))\n",
    "        \n",
    "        model_embedding = d2v_embeddings(data)\n",
    "        save_pkl(model_embedding, os.path.join(model_embeddings_path, f'd2v_{cuisine}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n"
     ]
    }
   ],
   "source": [
    "train_model_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I dont think we need to run this?\n",
    "def infer_cuisine_type_on_recipes(data):\n",
    "    model_path = os.path.join(model_path, 'pickle_model.pkl')\n",
    "    model = load_pkl(model_path)\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H. Final functions for Chatbot construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Predict Cuisine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cuisine(input_text):\n",
    "    top = 5\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text)\n",
    "    \n",
    "    # Get model\n",
    "    model_def = os.path.join(model_path, 'pickle_model.pkl')\n",
    "    model = load_pkl(model_def)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text)\n",
    "\n",
    "    # Get classes ordered by probability\n",
    "    proba = model.predict_proba([tokenize_text])[0]\n",
    "\n",
    "    # Sorted index list \n",
    "    indexes = sorted(range(len(proba)), key = lambda k: proba[k], reverse=True)\n",
    "\n",
    "    # Get cuisine\n",
    "    cuisine_labels = model.classes_.tolist()\n",
    "    cusine_ordered = [cuisine_labels[ind] for ind in indexes]\n",
    "\n",
    "    return cusine_ordered[: top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Getting similar recipes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_recipes(input_text, cuisine, top_k = 3):\n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text).split()\n",
    "    \n",
    "    # Load model from the selected cuisine\n",
    "    d2v = load_pkl(os.path.join(model_embeddings_path, f'd2v_{cuisine}.pkl'))\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = d2v.infer_vector(tokenize_text)\n",
    "    best_recipes = d2v.docvecs.most_similar([embeddings]) #gives you top 10 document tags and their cosine similarity\n",
    "\n",
    "    # Get recipes\n",
    "    best_recipes_index = [int(output[0]) for output in best_recipes]\n",
    "    \n",
    "    # Get dDtaFrame\n",
    "    df = get_df_from_db(cuisine)\n",
    "    \n",
    "    return df[df.index.isin(best_recipes_index)].head(top_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Link from Kaggle: https://www.kaggle.com/code/rahulsridhar2811/cuisine-classification-with-accuracy-78-88/notebook\n",
    "#### Additional:\n",
    "\n",
    "* https://htmlpreview.github.io/?https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/blob/master/AWS-lambda-implementation/model_implementation/recipe_binary_classification/recipe%20binary%20classification.html#Naive-Bayes\n",
    "* https://htmlpreview.github.io/?https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/blob/master/AWS-lambda-implementation/model_implementation/recipe_multiclass_classification/recipe%20multiclass%20classification.html#Logistic-Regression\n",
    "* https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/tree/master/AWS-lambda-implementation/model_implementation/recipe_multiclass_classification  \n",
    "\n",
    "\n",
    "* https://github.com/RomainGratier/recipes-telegram-bot\n",
    "* https://towardsdatascience.com/a-recommendation-engine-that-proposes-recipes-after-taking-photos-of-your-ingredients-de2d314f565d?source=friends_link&sk=c5280f8c50aa5551d1b36619891e9b4f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Telegram Chatbot Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Defining the initial arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parser\n",
    "my_parser = argparse.ArgumentParser(description ='Give your personal token')\n",
    "\n",
    "# Add the arguments\n",
    "my_parser.add_argument('token', metavar='token', type=str, help='The token given by Fatherbot')\n",
    "\n",
    "\n",
    "# Enable logging\n",
    "logging.basicConfig(\n",
    "    #filename= 'telgramBot.log',\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Main interactions ----\n",
    "CHOOSING, GET_TEXT = range(2)\n",
    "# Callback data\n",
    "CALLBACK1, CALLBACK2 = range(3,5)\n",
    "\n",
    "reply_keyboard = [\n",
    "    ['Show ingredients', 'Get recipes'],\n",
    "    ['Remove item', 'Done'],\n",
    "]\n",
    "markup = ReplyKeyboardMarkup(reply_keyboard, one_time_keyboard=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Functions for the chatbot flow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: Start\")\n",
    "\n",
    "    context.user_data['chat_id'] = update.message.chat_id\n",
    "\n",
    "    update.message.reply_text(\n",
    "        \"Hi! I am you recipe bot. What ingredients do you currently have?\"\n",
    "        \"You can add ingredients by typing it in one or two words\",\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n",
    "\n",
    "\n",
    "def get_basket_txt(list_ingredients):\n",
    "    txt = 'Here are your current ingredients:\\n'\n",
    "    for ingredient in list_ingredients:\n",
    "        txt += f'   - {ingredient}\\n'\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def button1(update: Update, context: CallbackContext) -> int:\n",
    "    logger.info(f\": button1\")\n",
    "\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "\n",
    "    user_data = context.user_data    \n",
    "    if 'ingredients_list' not in user_data:\n",
    "        user_data['ingredients_list'] = [query.data]\n",
    "    else:\n",
    "        user_data['ingredients_list'].append(query.data)\n",
    "\n",
    "    query.edit_message_text(text=f\"Ok you selected: {query.data}\")\n",
    "    \n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    context.bot.send_message(chat_id=context.user_data['chat_id'], text=txt)\n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "\n",
    "def recipes_query(update: Update, context: CallbackContext) -> int:\n",
    "    \"\"\" Get recipes \"\"\"\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: recipes_query\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "\n",
    "    input_text = ' '.join(user_data['ingredients_list'])\n",
    "\n",
    "    # Predict cuisine\n",
    "    cuisine = predict_cuisine(input_text)\n",
    "\n",
    "    keyboard = [\n",
    "        [\n",
    "            InlineKeyboardButton(cuisine[0], callback_data=cuisine[0]),\n",
    "            InlineKeyboardButton(cuisine[1], callback_data=cuisine[1]),\n",
    "            InlineKeyboardButton(cuisine[2], callback_data=cuisine[2])],\n",
    "        [\n",
    "            InlineKeyboardButton(cuisine[3], callback_data=cuisine[3]),\n",
    "            InlineKeyboardButton(cuisine[4], callback_data=cuisine[4]),\n",
    "        ]\n",
    "    ]\n",
    "    reply_markup = InlineKeyboardMarkup(keyboard)\n",
    "    # Send message with text and appended InlineKeyboard\n",
    "    update.message.reply_text(\"Chose the type of cuisine you want!\", reply_markup=reply_markup)\n",
    "\n",
    "    return CALLBACK2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def button2(update: Update, context: CallbackContext) -> int:\n",
    "    #user = update.message.from_user\n",
    "    logger.info(f\"button2\")\n",
    "\n",
    "    query = update.callback_query\n",
    "    query.answer()\n",
    "\n",
    "    # Get recipes\n",
    "    recipes = get_similar_recipes(context.user_data['ingredients_list'], query.data)\n",
    "\n",
    "    sep = '\\n\\n'\n",
    "    for index, row in recipes.iterrows():\n",
    "\n",
    "        title = 'Title: ' + row['title'] \n",
    "        ingredients=''\n",
    "        list_ing = row['ingredients'].replace('ADVERTISEMENT', '').strip('][').split(', ')\n",
    "        for ingredient in list_ing:\n",
    "            ingredients+= ingredient.replace(\"'\", \"\") + '\\n'\n",
    "        ingredients = 'Ingredients: ' + '\\n' + ingredients\n",
    "        instructions = 'Instruction: '+ '\\n' + row['instructions']\n",
    "\n",
    "        txt = title + sep + ingredients + sep + instructions\n",
    "\n",
    "        context.bot.send_message(chat_id=context.user_data['chat_id'], text=txt)\n",
    "\n",
    "    return CHOOSING\n",
    "\n",
    "\n",
    "def show_basket(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: show_basket\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    \n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    \n",
    "    update.message.reply_text(\n",
    "        txt,\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n",
    "\n",
    "\n",
    "def received_text_information(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: received_text_information\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    text = update.message.text\n",
    "    \n",
    "    if 'ingredients_list' not in user_data:\n",
    "        user_data['ingredients_list'] = [text]\n",
    "    else:\n",
    "        user_data['ingredients_list'].append(text)\n",
    "\n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    update.message.reply_text(\n",
    "        txt,\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n",
    "\n",
    "\n",
    "def remove_item(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: remove_item\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    if 'ingredients_list' in user_data:\n",
    "        del user_data['ingredients_list'][-1]\n",
    "    \n",
    "    introduction = 'You have deleted the last ingredient. '\n",
    "    txt = get_basket_txt(user_data['ingredients_list'])\n",
    "    update.message.reply_text(\n",
    "        introduction + txt,\n",
    "        reply_markup=markup,\n",
    "    )\n",
    "    return CHOOSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def done(update: Update, context: CallbackContext) -> int:\n",
    "    user = update.message.from_user\n",
    "    logger.info(f\"{user.first_name}: done\")\n",
    "\n",
    "    user_data = context.user_data\n",
    "    if 'ingredients_list' in user_data:\n",
    "        del user_data['ingredients_list']\n",
    "\n",
    "    update.message.reply_text(\n",
    "        f\"Bye bye until next time!\"\n",
    "    )\n",
    "\n",
    "    user_data.clear()\n",
    "    return ConversationHandler.END    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(bot_token) -> None:\n",
    "    updater = Updater(bot_token, use_context=True)\n",
    "\n",
    "    # Get the dispatcher to register handlers\n",
    "    dispatcher = updater.dispatcher\n",
    "\n",
    "    # Add conversation handler with the states CHOOSING, TYPING_CHOICE and TYPING_REPLY\n",
    "    conv_handler = ConversationHandler(\n",
    "        entry_points=[CommandHandler('start', start)],\n",
    "        states={\n",
    "            CHOOSING: [\n",
    "                MessageHandler(Filters.text & ~(Filters.command | Filters.regex('^(Done|Get recipes|Show ingredients|Remove item)$')), received_text_information),\n",
    "                MessageHandler(Filters.regex('^Get recipes$'), recipes_query),\n",
    "                MessageHandler(Filters.regex('^Show ingredients$'), show_basket),\n",
    "                MessageHandler(Filters.regex('^Remove item$'), remove_item),\n",
    "            ],\n",
    "            CALLBACK1: [\n",
    "                CallbackQueryHandler(button1)],\n",
    "            CALLBACK2: [\n",
    "                CallbackQueryHandler(button2)],\n",
    "        },\n",
    "        fallbacks=[MessageHandler(Filters.regex('^Done$'), done)],\n",
    "        per_message=False,\n",
    "    )\n",
    "\n",
    "    dispatcher.add_handler(conv_handler)\n",
    "    \n",
    "    updater.start_polling()\n",
    "    updater.idle()\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        args = my_parser.parse_args()\n",
    "        main(args.token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Demonstrate using Bot token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-14 19:40:56,603 - apscheduler.scheduler - INFO - Scheduler started\n",
      "2022-04-14 19:41:02,334 - __main__ - INFO - SJ: Start\n",
      "2022-04-14 19:41:03,467 - __main__ - INFO - SJ: received_text_information\n",
      "2022-04-14 19:41:07,861 - __main__ - INFO - SJ: received_text_information\n",
      "2022-04-14 19:41:09,512 - __main__ - INFO - SJ: recipes_query\n",
      "2022-04-14 19:41:12,129 - __main__ - INFO - button2\n",
      "2022-04-14 19:41:29,404 - __main__ - INFO - SJ: done\n",
      "2022-04-14 19:42:38,374 - telegram.ext.updater - INFO - Received signal 2 (SIGINT), stopping...\n",
      "2022-04-14 19:42:38,378 - apscheduler.scheduler - INFO - Scheduler has been shut down\n",
      "usage: ipykernel_launcher.py [-h] token\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "#Need to have telegram and Botfather enabled to access the same!\n",
    "main('5320161288:AAFF7KGZhNR7QjsC5vUlwf8jBH0jE-cyLM4') "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5db968608ecdb27000edf98c5f63e9ccc25d479a7a16895421f990979c50088b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
