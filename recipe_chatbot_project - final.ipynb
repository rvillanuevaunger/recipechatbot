{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Recipe Chatbot Project</center></h1>\n",
    "<h2><center>DATA-641</center></h2>\n",
    "<h3><center>Sobanaa Jayakumar & Reina Villanueva-Unger</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "### A. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data processing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "#feature engg\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#model & processing libraries\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold\n",
    "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
    "from sklearn import feature_selection\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn import utils\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "#Sampling \n",
    "from imblearn import pipeline as pl\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Embeddings\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "#DB accesses\n",
    "import sqlite3 as sq\n",
    "\n",
    "#to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Set Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Data Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_path = \"data/cuisine_data/\"\n",
    "recipes_path = \"data/recipes_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Model Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"models/nlp\"\n",
    "model_embeddings_path = os.path.join(model_path, 'similarity_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Data Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuisine data\n",
    "def import_cuisine_data(): \n",
    "    train = pd.read_json(os.path.join(cuisine_path, 'train.json'))\n",
    "    return train\n",
    "\n",
    "#Recipe Data \n",
    "def import_recipe_data():\n",
    "    all_recipes = pd.read_json('./data/recipes_data/recipes_raw_nosource_allrecipes.json', orient='index')\n",
    "    epicurious = pd.read_json('./data/recipes_data/recipes_raw_nosource_epicurious.json', orient='index')\n",
    "    food_network = pd.read_json('./data/recipes_data/recipes_raw_nosource_foodnetwork.json', orient='index')\n",
    "    data = pd.concat([all_recipes, epicurious, food_network], axis=0)\n",
    "    \n",
    "    data = data.reset_index()\n",
    "    data = data.drop(columns=['index', 'picture_link'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Set Cuisine Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_classes = ['greek','southern_us','filipino','indian','jamaican','spanish','italian','mexican','chinese','british','thai','vietnamese','cajun_creole','brazilian','french','japanese','irish','korean','moroccan','russian']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stop_words = [\"advertisement\", \"advertisements\",\n",
    "                         \"cup\", \"cups\",\n",
    "                         \"tablespoon\", \"tablespoons\", \n",
    "                         \"teaspoon\", \"teaspoons\", \n",
    "                         \"ounce\", \"ounces\",\n",
    "                         \"salt\", \n",
    "                         \"pepper\", \n",
    "                         \"pound\", \"pounds\",\n",
    "                         ]\n",
    "\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "stopword_list.extend(additional_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>29109</td>\n",
       "      <td>irish</td>\n",
       "      <td>[light brown sugar, granulated sugar, butter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>11462</td>\n",
       "      <td>italian</td>\n",
       "      <td>[KRAFT Zesty Italian Dressing, purple onion, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>2238</td>\n",
       "      <td>irish</td>\n",
       "      <td>[eggs, citrus fruit, raisins, sourdough starte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39772</th>\n",
       "      <td>41882</td>\n",
       "      <td>chinese</td>\n",
       "      <td>[boneless chicken skinless thigh, minced garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>2362</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[green chile, jalapeno chilies, onions, ground...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39774 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      cuisine                                        ingredients\n",
       "0      10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1      25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2      20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3      22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4      13162       indian  [black pepper, shallots, cornflour, cayenne pe...\n",
       "...      ...          ...                                                ...\n",
       "39769  29109        irish  [light brown sugar, granulated sugar, butter, ...\n",
       "39770  11462      italian  [KRAFT Zesty Italian Dressing, purple onion, b...\n",
       "39771   2238        irish  [eggs, citrus fruit, raisins, sourdough starte...\n",
       "39772  41882      chinese  [boneless chicken skinless thigh, minced garli...\n",
       "39773   2362      mexican  [green chile, jalapeno chilies, onions, ground...\n",
       "\n",
       "[39774 rows x 3 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_cuisine_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. String Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. String Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(list, lemmatize = True, stemming = False, lst_stopwords=None):\n",
    "    str = ' '.join(list) #converting the list to string\n",
    "    clean_text = ''\n",
    "    \n",
    "    lower = str.lower().split() #lowercase and tokenize\n",
    "    \n",
    "    lst_text = []\n",
    "    clean_words = []\n",
    "    for word in lower:\n",
    "        if len(word) > 2:\n",
    "            digit = re.sub(r'\\d+','', word) #removing digits\n",
    "            text = re.sub(r'[^\\w\\s]', '', digit) #removing punc and characters\n",
    "            \n",
    "            \n",
    "            if lemmatize:\n",
    "                lm = WordNetLemmatizer()  #lemmatize\n",
    "                lemm = lm.lemmatize(text)\n",
    "                clean_words.append(lemm)\n",
    "                \n",
    "                if stemming:\n",
    "                    stemmer = PorterStemmer #stemming\n",
    "                    stemm = stemmer.stem(text)\n",
    "                    clean_words.append(stemm)\n",
    "         \n",
    "    #if lst_stopwords is not None:\n",
    "        #lst_text = [word for word in lst_text if word not in \n",
    "                    #lst_stopwords] #remove stopwords\n",
    "    \n",
    "    clean_text = ' '.join(lst_text) #join as a string\n",
    "    text = re.sub(' +', ' ', clean_text) #remove multi-spaces\n",
    "    \n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cuisine(): # !!!--- NEED TO UPDATE LATER IN CODE ---!!! originally: process_data()\n",
    "    cuisine_data = import_cuisine_data() # cuisine\n",
    "\n",
    "    def processing(row):\n",
    "        ls = row['ingredients']\n",
    "        return ' '.join(ls)\n",
    "\n",
    "    cuisine_data['ingredients'] = cuisine_data.apply(lambda x: processing(x), axis=1)\n",
    "    cuisine_data.dropna(inplace=True)\n",
    "    cuisine_data = cuisine_data.drop(columns=['id']).reset_index(drop=True)\n",
    "\n",
    "    cuisine_data[\"ingredients_query\"] = cuisine_data[\"ingredients\"].apply(lambda x: \n",
    "          clean_text(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return cuisine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recipes(data): # Recipes dataset\n",
    "    data[\"ingredients_query\"] = data[\"ingredients\"].apply(lambda x: \n",
    "            clean_text(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return data\n",
    "\n",
    "def get_tokenize_text(input_text):\n",
    "    return clean_text(iclean_textnput_text, stemming=False, lemmatize=True, lst_stopwords=stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_data = process_cuisine()\n",
    "X = cuisine_data['ingredients_query']\n",
    "y = cuisine_data['cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_cuisine_predictions():\n",
    "    # Classifer\n",
    "    classifier = LogisticRegression(random_state=123,\n",
    "                                      max_iter=300,\n",
    "                                      n_jobs=-1,\n",
    "                                      multi_class = 'multinomial', \n",
    "                                      solver = 'lbfgs', \n",
    "                                      C = 10, \n",
    "                                      penalty = 'l2',\n",
    "                                      verbose=1\n",
    "                                      ) \n",
    "    ## pipeline\n",
    "    model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                                (\"classifier\", classifier)])\n",
    "\n",
    "    #Fitting Vectorizer\n",
    "    #matrix_train_lr = vectorizer.fit_transform(X_train)\n",
    "    #matrix_test_lr = vectorizer.transform(X_test)\n",
    "\n",
    "    # Fit Model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_train)\n",
    "\n",
    "    # Save as Pkl\n",
    "    save_pkl(model, os.path.join(model_path, \"pickle_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/nlp'\n",
    "\n",
    "def create_and_populate_db():\n",
    "    data = import_recipe_data()\n",
    "    \n",
    "    # Process the data\n",
    "    data = process_recipes(data)\n",
    "    \n",
    "    # Predict cuisine from trained model\n",
    "    model = load_pkl(os.path.join(model_path, 'pickle_model.pkl'))\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"].tolist())  #this is predicting cuisine for recipe dataset\n",
    "    \n",
    "    db = sq.connect('recipes.db')\n",
    "    #Verify dtypes\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype('str')\n",
    "\n",
    "    print(' ------------------ Check data before populating the db ------------------')\n",
    "    print(data.columns)\n",
    "    print(data.head())\n",
    "    print(data.shape)\n",
    "    data.to_sql('main_recipes', db, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing function - From the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this function!!!\n",
    "def clean_string(text, stemming=False, lemmatize=True, lst_stopwords=None):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "     \n",
    "    lst_text = []    \n",
    "    ## Tokenize (convert from string to list)\n",
    "    if len(text) > 2:\n",
    "        lst_text = text.split()\n",
    "\n",
    "    ## remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in \n",
    "                    lst_stopwords]\n",
    "                \n",
    "    ## Stemming (remove -ing, -ly, ...)\n",
    "    if stemming == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if lemmatize == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "\n",
    "    ## Remove digits\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "\n",
    "    ## remove mutliple space\n",
    "    text = re.sub(' +', ' ', text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Preprocess Cuisine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cuisine(): # !!!--- NEED TO UPDATE LATER IN CODE ---!!! originally: process_data()\n",
    "    cuisine_data = import_cuisine_data() # cuisine\n",
    "\n",
    "    def processing(row):\n",
    "        ls = row['ingredients']\n",
    "        return ' '.join(ls)\n",
    "\n",
    "    cuisine_data['ingredients'] = cuisine_data.apply(lambda x: processing(x), axis=1)\n",
    "    cuisine_data.dropna(inplace=True)\n",
    "    cuisine_data = cuisine_data.drop(columns=['id']).reset_index(drop=True)\n",
    "\n",
    "    cuisine_data[\"ingredients_query\"] = cuisine_data[\"ingredients\"].apply(lambda x: \n",
    "          clean_string(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return cuisine_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Preprocess Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_recipes(data): # Recipes dataset\n",
    "    data[\"ingredients_query\"] = data[\"ingredients\"].apply(lambda x: \n",
    "            clean_string(x, stemming=False, lemmatize=True, lst_stopwords=stopword_list))\n",
    "    return data\n",
    "\n",
    "def get_tokenize_text(input_text):\n",
    "    return clean_string(input_text, stemming=False, lemmatize=True, lst_stopwords=stopword_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Defining variables - Cuisine subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_subset = process_cuisine().sample(n = 17000)\n",
    "X_s = cuisine_subset['ingredients_query']\n",
    "y_s = cuisine_subset['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Defining variables - Cuisine full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_data = process_cuisine()\n",
    "X = cuisine_data['ingredients_query']\n",
    "y = cuisine_data['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cuisine Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Defining vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Defining Test_train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Tested Multiple Categorization Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.a. Logistic Regression - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 500, random_state = 123, multi_class = 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 10\n",
      "Best Solver: lbfgs\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "penalty = ['l2', 'l1', 'elasticnet']\n",
    "C = [0.001, 0.01, 0.1, 10]\n",
    "solvers = ['newton-cg', 'lbfgs']\n",
    "\n",
    "#Fitting into pipeline\n",
    "lr_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('lr', lr)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(lr__C = C, lr__penalty = penalty, lr__solver = solvers)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(lr_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['lr__penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['lr__C'])\n",
    "print('Best Solver:', best_model.best_estimator_.get_params()['lr__solver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i.b. Logistic Regression - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7835600708811891\n",
      "Accuracy score 0.7874094931617055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.80      0.57      0.67       117\n",
      "     british       0.61      0.45      0.52       201\n",
      "cajun_creole       0.78      0.69      0.73       386\n",
      "     chinese       0.81      0.87      0.84       668\n",
      "    filipino       0.79      0.57      0.66       189\n",
      "      french       0.58      0.67      0.62       662\n",
      "       greek       0.77      0.69      0.72       294\n",
      "      indian       0.87      0.91      0.89       751\n",
      "       irish       0.69      0.49      0.57       167\n",
      "     italian       0.81      0.89      0.84      1960\n",
      "    jamaican       0.92      0.71      0.80       131\n",
      "    japanese       0.85      0.69      0.76       356\n",
      "      korean       0.86      0.75      0.80       207\n",
      "     mexican       0.91      0.91      0.91      1610\n",
      "    moroccan       0.81      0.77      0.79       205\n",
      "     russian       0.65      0.45      0.53       122\n",
      " southern_us       0.72      0.81      0.76      1080\n",
      "     spanish       0.61      0.47      0.53       247\n",
      "        thai       0.74      0.81      0.77       385\n",
      "  vietnamese       0.68      0.48      0.56       206\n",
      "\n",
      "    accuracy                           0.79      9944\n",
      "   macro avg       0.76      0.68      0.71      9944\n",
      "weighted avg       0.79      0.79      0.78      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train_lr = vectorizer.fit_transform(X_train)\n",
    "matrix_test_lr = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "lr_final = LogisticRegression(max_iter = 300, random_state = 123, multi_class ='multinomial', solver = 'lbfgs', C = 10, penalty = 'l2')\n",
    "lr_final.fit(matrix_train_lr, y_train)\n",
    "y_pred = lr_final.predict(matrix_test_lr)\n",
    "pred_prob = lr_final.predict_proba(matrix_test_lr)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, pred_prob))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#cm_lr_test=confusion_matrix(y_test, y_pred)\n",
    "#print(cm_lr_test)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred)\n",
    "f1_lr = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ii.a. Multinomial Naive Bayes - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.01\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params\n",
    "alpha = [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "\n",
    "#Fitting into pipeline\n",
    "nb_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('nb', nb)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(nb__alpha = alpha)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(nb_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Alpha:', best_model.best_estimator_.get_params()['nb__alpha'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii.b. Multinomial Naive Bayes - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.736116043309851\n",
      "Accuracy score 0.7412510056315366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.71      0.47      0.57       117\n",
      "     british       0.52      0.41      0.46       201\n",
      "cajun_creole       0.66      0.69      0.68       386\n",
      "     chinese       0.76      0.88      0.81       668\n",
      "    filipino       0.81      0.49      0.61       189\n",
      "      french       0.52      0.60      0.56       662\n",
      "       greek       0.74      0.56      0.64       294\n",
      "      indian       0.84      0.87      0.86       751\n",
      "       irish       0.71      0.44      0.54       167\n",
      "     italian       0.78      0.85      0.81      1960\n",
      "    jamaican       0.85      0.58      0.69       131\n",
      "    japanese       0.85      0.64      0.73       356\n",
      "      korean       0.88      0.65      0.75       207\n",
      "     mexican       0.88      0.88      0.88      1610\n",
      "    moroccan       0.76      0.70      0.73       205\n",
      "     russian       0.66      0.34      0.45       122\n",
      " southern_us       0.63      0.75      0.68      1080\n",
      "     spanish       0.58      0.37      0.45       247\n",
      "        thai       0.66      0.78      0.71       385\n",
      "  vietnamese       0.63      0.43      0.51       206\n",
      "\n",
      "    accuracy                           0.74      9944\n",
      "   macro avg       0.72      0.62      0.66      9944\n",
      "weighted avg       0.74      0.74      0.74      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb_final = MultinomialNB(alpha = 0.01)\n",
    "nb_final.fit(matrix_train, y_train)\n",
    "y_pred = nb_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average ='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_mnb = accuracy_score(y_test, y_pred)\n",
    "f1_mnb = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.a. Random Forest - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: 500\n",
      "Best features: sqrt\n",
      "Best samples split: 2\n",
      "Best samples leaf: 5\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "n_estimators = [10, 100, 500]\n",
    "max_features = ['sqrt', 'log2']\n",
    "min_samples_split = [2, 10, 100]\n",
    "min_samples_leaf = [5, 10] \n",
    "\n",
    "\n",
    "#Fitting into pipeline\n",
    "rf_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('rf', rf)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(rf__n_estimators = estimators, rf__max_features = max_features, rf__min_samples_split = min_samples_split, rf__min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(rf_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Estimator:', best_model.best_estimator_.get_params()['rf__n_estimators'])\n",
    "print('Best features:', best_model.best_estimator_.get_params()['rf__max_features'])\n",
    "print('Best samples split:', best_model.best_estimator_.get_params()['rf__min_samples_split'])\n",
    "print('Best samples leaf:', best_model.best_estimator_.get_params()['rf__min_samples_leaf'])\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii.b. Random Forest - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.5706338276541044\n",
      "Accuracy score 0.6288213998390989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.85      0.24      0.37       117\n",
      "     british       1.00      0.00      0.01       201\n",
      "cajun_creole       0.89      0.49      0.63       386\n",
      "     chinese       0.61      0.90      0.72       668\n",
      "    filipino       1.00      0.07      0.14       189\n",
      "      french       0.58      0.20      0.30       662\n",
      "       greek       0.93      0.23      0.37       294\n",
      "      indian       0.78      0.86      0.82       751\n",
      "       irish       0.80      0.02      0.05       167\n",
      "     italian       0.56      0.92      0.69      1960\n",
      "    jamaican       1.00      0.12      0.22       131\n",
      "    japanese       0.96      0.46      0.62       356\n",
      "      korean       0.98      0.20      0.34       207\n",
      "     mexican       0.73      0.91      0.81      1610\n",
      "    moroccan       0.98      0.21      0.35       205\n",
      "     russian       0.00      0.00      0.00       122\n",
      " southern_us       0.47      0.71      0.56      1080\n",
      "     spanish       0.00      0.00      0.00       247\n",
      "        thai       0.68      0.66      0.67       385\n",
      "  vietnamese       0.76      0.08      0.14       206\n",
      "\n",
      "    accuracy                           0.63      9944\n",
      "   macro avg       0.73      0.36      0.39      9944\n",
      "weighted avg       0.67      0.63      0.57      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train_rf = vectorizer.fit_transform(X_train)\n",
    "matrix_test_rf = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "rf_final = RandomForestClassifier(random_state = 123, n_estimators = 500, max_features = 'sqrt', min_samples_split = 2, min_samples_leaf = 5)\n",
    "rf_final.fit(matrix_train_rf, y_train)\n",
    "y_pred = rf_final.predict(matrix_test_rf)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average ='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred)\n",
    "f1_rf = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.a. SVC - Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Kernel: sigmoid\n",
      "Best C: 10\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "kernel = ['rbf', 'poly', 'sigmoid']  \n",
    "C = [0.001, 0.01, 0.1, 10]\n",
    "\n",
    "#Fitting into pipeline\n",
    "svc_pipe = Pipeline([('vect', vectorizer),\n",
    "                      #('densify', SparseToDense()),\n",
    "                      #('scale', StandardScaler()),\n",
    "                      ('svc', svc)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(svc__kernel = kernel, svc__C = C)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(svc_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X_s, y_s)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Kernel:', best_model.best_estimator_.get_params()['svc__kernel'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['svc__C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv.b. SVC - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7521964647011117\n",
      "Accuracy score 0.7526146419951729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.67      0.65      0.66       117\n",
      "     british       0.49      0.53      0.51       201\n",
      "cajun_creole       0.71      0.69      0.70       386\n",
      "     chinese       0.79      0.84      0.81       668\n",
      "    filipino       0.67      0.61      0.64       189\n",
      "      french       0.50      0.64      0.56       662\n",
      "       greek       0.68      0.69      0.68       294\n",
      "      indian       0.85      0.88      0.86       751\n",
      "       irish       0.51      0.47      0.49       167\n",
      "     italian       0.80      0.82      0.81      1960\n",
      "    jamaican       0.85      0.76      0.80       131\n",
      "    japanese       0.76      0.68      0.72       356\n",
      "      korean       0.84      0.74      0.78       207\n",
      "     mexican       0.89      0.89      0.89      1610\n",
      "    moroccan       0.77      0.76      0.77       205\n",
      "     russian       0.57      0.41      0.48       122\n",
      " southern_us       0.73      0.70      0.71      1080\n",
      "     spanish       0.55      0.43      0.49       247\n",
      "        thai       0.76      0.78      0.77       385\n",
      "  vietnamese       0.62      0.50      0.55       206\n",
      "\n",
      "    accuracy                           0.75      9944\n",
      "   macro avg       0.70      0.67      0.68      9944\n",
      "weighted avg       0.75      0.75      0.75      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "svc_final = SVC(random_state = 123, kernel = 'sigmoid', C = 10)\n",
    "svc_final.fit(matrix_train, y_train)\n",
    "y_pred = svc_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred)\n",
    "f1_svm = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v.a. XGB - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBClassifier(objective = 'multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth: 1\n",
      "Best Gamma: 1\n",
      "Best Alpha: 1\n",
      "Best Lambda: 0\n",
      "Best Colsample: 0.5\n",
      "Best Child weight: 1\n",
      "Best ETA: 0.5\n"
     ]
    }
   ],
   "source": [
    "max_depth = [1, 5, 20, 50]\n",
    "gamma = [1, 10]\n",
    "reg_alpha = [1, 40, 180]\n",
    "reg_lambda = [0, 1]\n",
    "colsample_bytree = [0.5, 1]\n",
    "min_child_weight = [0, 1, 10]\n",
    "eta = [0.5, 1]\n",
    "\n",
    "\n",
    "xgb_pipe = Pipeline([('vect', vectorizer),\n",
    "                      ('xgb', xgb)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(xgb__max_depth = max_depth, xgb__gamma = gamma, xgb__reg_alpha = reg_alpha, \n",
    "                       xgb__reg_lambda = reg_lambda, xgb__colsample_bytree = colsample_bytree, xgb__min_child_weight = min_child_weight, xgb__eta = eta)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(xgb_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X_s, y_s)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Depth:', best_model.best_estimator_.get_params()['xgb__max_depth'])\n",
    "print('Best Gamma:', best_model.best_estimator_.get_params()['xgb__gamma'])\n",
    "print('Best Alpha:', best_model.best_estimator_.get_params()['xgb__reg_alpha'])\n",
    "print('Best Lambda:', best_model.best_estimator_.get_params()['xgb__reg_lambda'])\n",
    "print('Best Colsample:', best_model.best_estimator_.get_params()['xgb__colsample_bytree'])\n",
    "print('Best Child weight:', best_model.best_estimator_.get_params()['xgb__min_child_weight'])\n",
    "print('Best ETA:', best_model.best_estimator_.get_params()['xgb__eta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v.b. XGB - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7377902089531876\n",
      "Accuracy score 0.7453740949316171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.78      0.53      0.63       117\n",
      "     british       0.50      0.24      0.33       201\n",
      "cajun_creole       0.79      0.67      0.73       386\n",
      "     chinese       0.78      0.84      0.81       668\n",
      "    filipino       0.68      0.48      0.57       189\n",
      "      french       0.54      0.55      0.54       662\n",
      "       greek       0.81      0.70      0.75       294\n",
      "      indian       0.86      0.86      0.86       751\n",
      "       irish       0.62      0.43      0.50       167\n",
      "     italian       0.70      0.88      0.78      1960\n",
      "    jamaican       0.89      0.67      0.77       131\n",
      "    japanese       0.85      0.65      0.73       356\n",
      "      korean       0.79      0.66      0.72       207\n",
      "     mexican       0.88      0.89      0.89      1610\n",
      "    moroccan       0.81      0.71      0.76       205\n",
      "     russian       0.58      0.34      0.43       122\n",
      " southern_us       0.66      0.76      0.70      1080\n",
      "     spanish       0.63      0.35      0.45       247\n",
      "        thai       0.75      0.79      0.77       385\n",
      "  vietnamese       0.68      0.43      0.53       206\n",
      "\n",
      "    accuracy                           0.75      9944\n",
      "   macro avg       0.73      0.62      0.66      9944\n",
      "weighted avg       0.74      0.75      0.74      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params. Import xgb before running this\n",
    "xgb_final = xgb.XGBClassifier(objective = 'multi:softmax', max_depth = 1, gamma = 1, reg_alpha = 1, \n",
    "                     reg_lambda = 0, colsample_bytree = 0.5, min_child_weight = 1, eta = 0.5, eval_metric = 'mlogloss')\n",
    "\n",
    "xgb_final.fit(matrix_train, y_train)\n",
    "y_pred = xgb_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred)\n",
    "f1_xgb = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi.a. Over and Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_samp = LogisticRegression(max_iter = 300, random_state = 123, multi_class = 'multinomial',  solver = 'newton-cg', C = 10, penalty = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_os = RandomOverSampler(random_state=123)\n",
    "random_us = RandomUnderSampler(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi.b. Oversampling LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on oversampling:\n",
      "\n",
      "f1 score weighted 0.7856498439972385\n",
      "Accuracy score 0.7844931617055511\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   brazilian       0.70      0.68      1.00      0.69      0.82      0.65       117\n",
      "     british       0.53      0.57      0.99      0.55      0.75      0.54       201\n",
      "cajun_creole       0.74      0.75      0.99      0.74      0.86      0.72       386\n",
      "     chinese       0.82      0.85      0.99      0.83      0.91      0.82       668\n",
      "    filipino       0.72      0.65      0.99      0.68      0.80      0.63       189\n",
      "      french       0.58      0.68      0.96      0.62      0.81      0.63       662\n",
      "       greek       0.71      0.77      0.99      0.74      0.87      0.74       294\n",
      "      indian       0.89      0.90      0.99      0.90      0.95      0.89       751\n",
      "       irish       0.57      0.57      0.99      0.57      0.75      0.54       167\n",
      "     italian       0.85      0.83      0.96      0.84      0.89      0.79      1960\n",
      "    jamaican       0.83      0.79      1.00      0.81      0.89      0.78       131\n",
      "    japanese       0.83      0.72      0.99      0.77      0.85      0.70       356\n",
      "      korean       0.81      0.79      1.00      0.80      0.89      0.77       207\n",
      "     mexican       0.93      0.90      0.99      0.91      0.94      0.88      1610\n",
      "    moroccan       0.74      0.81      0.99      0.78      0.90      0.79       205\n",
      "     russian       0.55      0.52      0.99      0.54      0.72      0.50       122\n",
      " southern_us       0.76      0.77      0.97      0.77      0.86      0.73      1080\n",
      "     spanish       0.52      0.52      0.99      0.52      0.72      0.49       247\n",
      "        thai       0.74      0.78      0.99      0.76      0.88      0.76       385\n",
      "  vietnamese       0.62      0.54      0.99      0.58      0.73      0.52       206\n",
      "\n",
      " avg / total       0.79      0.78      0.98      0.79      0.88      0.76      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_os = pl.make_pipeline(vectorizer,\n",
    "                           random_os,\n",
    "                           lr_samp)\n",
    "\n",
    "\n",
    "# Train the classifier with balancing\n",
    "lr_pipe_os.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = lr_pipe_os.predict(X_test)\n",
    "\n",
    "print(\"results on oversampling:\\n\")\n",
    "\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred_bal, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred_bal))\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "\n",
    "acc_os_lr = accuracy_score(y_test, y_pred_bal)\n",
    "f1_os_lr = f1_score(y_test, y_pred_bal, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi.c. Undersampling LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on Undersampling:\n",
      "\n",
      "f1 score weighted 0.7209825708033166\n",
      "Accuracy score 0.7059533386967015\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   brazilian       0.41      0.76      0.99      0.54      0.87      0.73       117\n",
      "     british       0.31      0.61      0.97      0.41      0.77      0.57       201\n",
      "cajun_creole       0.63      0.76      0.98      0.69      0.86      0.73       386\n",
      "     chinese       0.85      0.77      0.99      0.81      0.87      0.75       668\n",
      "    filipino       0.49      0.68      0.99      0.57      0.82      0.65       189\n",
      "      french       0.51      0.54      0.96      0.52      0.72      0.49       662\n",
      "       greek       0.60      0.79      0.98      0.68      0.88      0.76       294\n",
      "      indian       0.91      0.83      0.99      0.87      0.91      0.81       751\n",
      "       irish       0.35      0.63      0.98      0.45      0.79      0.59       167\n",
      "     italian       0.89      0.67      0.98      0.76      0.81      0.63      1960\n",
      "    jamaican       0.62      0.83      0.99      0.71      0.91      0.81       131\n",
      "    japanese       0.80      0.67      0.99      0.73      0.82      0.65       356\n",
      "      korean       0.70      0.77      0.99      0.74      0.88      0.75       207\n",
      "     mexican       0.95      0.81      0.99      0.87      0.90      0.79      1610\n",
      "    moroccan       0.60      0.84      0.99      0.70      0.91      0.82       205\n",
      "     russian       0.33      0.67      0.98      0.44      0.81      0.64       122\n",
      " southern_us       0.79      0.58      0.98      0.67      0.75      0.55      1080\n",
      "     spanish       0.34      0.60      0.97      0.43      0.76      0.56       247\n",
      "        thai       0.75      0.73      0.99      0.74      0.85      0.70       385\n",
      "  vietnamese       0.53      0.64      0.99      0.58      0.79      0.61       206\n",
      "\n",
      " avg / total       0.76      0.71      0.98      0.72      0.83      0.68      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_us = pl.make_pipeline(vectorizer,\n",
    "                           random_us,\n",
    "                           lr_samp)\n",
    "\n",
    "\n",
    "\n",
    "# Train the classifier with balancing\n",
    "lr_pipe_us.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = lr_pipe_us.predict(X_test)\n",
    "\n",
    "print(\"results on Undersampling:\\n\")\n",
    "\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred_bal, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred_bal))\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "\n",
    "acc_us_lr = accuracy_score(y_test, y_pred_bal)\n",
    "f1_us_lr = f1_score(y_test, y_pred_bal, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Dataframe with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787409</td>\n",
       "      <td>0.783560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Oversampled</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.785650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.752615</td>\n",
       "      <td>0.752196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XG Boost Model</td>\n",
       "      <td>0.745374</td>\n",
       "      <td>0.737790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.741251</td>\n",
       "      <td>0.736116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression - Undersampled</td>\n",
       "      <td>0.705953</td>\n",
       "      <td>0.720983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.628821</td>\n",
       "      <td>0.570634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy Score  F1 Score\n",
       "0                 Logistic Regression        0.787409  0.783560\n",
       "3   Logistic Regression - Oversampled        0.784493  0.785650\n",
       "1             Support Vector Machines        0.752615  0.752196\n",
       "2                      XG Boost Model        0.745374  0.737790\n",
       "5                         Naive Bayes        0.741251  0.736116\n",
       "4  Logistic Regression - Undersampled        0.705953  0.720983\n",
       "6                       Random Forest        0.628821  0.570634"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machines', 'XG Boost Model', 'Logistic Regression - Oversampled', \n",
    "              'Logistic Regression - Undersampled', 'Naive Bayes', 'Random Forest'],\n",
    "    'Accuracy Score': [acc_lr, acc_svm, acc_xgb, acc_os_lr, acc_us_lr, acc_mnb, acc_rf],\n",
    "    'F1 Score': [f1_lr, f1_svm, f1_xgb, f1_os_lr, f1_us_lr, f1_mnb, f1_rf]})\n",
    "models.sort_values(by = 'Accuracy Score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Fitting Best Model - Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Saving & Loading Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load pkl\n",
    "def load_pkl(pkl_filename):\n",
    "    with open(pkl_filename, 'rb') as pkl_file:\n",
    "        return pickle.load(pkl_file)\n",
    "    \n",
    "## Save pkl\n",
    "def save_pkl(file, pkl_filename):\n",
    "    with open(pkl_filename, 'wb') as pkl_file:\n",
    "        pickle.dump(file, pkl_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii. Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_cuisine_predictions():\n",
    "    # Classifer\n",
    "    classifier = LogisticRegression(random_state=123,\n",
    "                                      max_iter=300,\n",
    "                                      n_jobs=-1,\n",
    "                                      multi_class = 'multinomial', \n",
    "                                      solver = 'lbfgs', \n",
    "                                      C = 10, \n",
    "                                      penalty = 'l2',\n",
    "                                      verbose=1\n",
    "                                      ) \n",
    "    ## pipeline\n",
    "    model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
    "                                (\"classifier\", classifier)])\n",
    "\n",
    "\n",
    "    # Fit Model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_prob = model.predict_proba(X_train)\n",
    "\n",
    "    # Save as Pkl\n",
    "    save_pkl(model, os.path.join(model_path, \"pickle_model.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iii. Check function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  5.4min finished\n"
     ]
    }
   ],
   "source": [
    "create_model_cuisine_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iv. Creating a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/nlp'\n",
    "\n",
    "def create_and_populate_db():\n",
    "    data = import_recipe_data()\n",
    "    \n",
    "    # Process the data\n",
    "    data = process_recipes(data)\n",
    "    \n",
    "    # Predict cuisine from trained model\n",
    "    model = load_pkl(os.path.join(model_path, 'pickle_model.pkl'))\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"].tolist())  #this is predicting cuisine for recipe dataset\n",
    "    \n",
    "    db = sq.connect('recipes.db')\n",
    "    #Verify dtypes\n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].astype('str')\n",
    "\n",
    "    print(' ------------------ Check data before populating the db ------------------')\n",
    "    print(data.columns)\n",
    "    print(data.head())\n",
    "    print(data.shape)\n",
    "    data.to_sql('main_recipes', db, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ------------------ Check data before populating the db ------------------\n",
      "Index(['title', 'ingredients', 'instructions', 'ingredients_query', 'cuisine'], dtype='object')\n",
      "                               title  \\\n",
      "0  Slow Cooker Chicken and Dumplings   \n",
      "1      Awesome Slow Cooker Pot Roast   \n",
      "2               Brown Sugar Meatloaf   \n",
      "3        Best Chocolate Chip Cookies   \n",
      "4  Homemade Mac and Cheese Casserole   \n",
      "\n",
      "                                         ingredients  \\\n",
      "0  ['4 skinless, boneless chicken breast halves A...   \n",
      "1  ['2 (10.75 ounce) cans condensed cream of mush...   \n",
      "2  ['1/2 cup packed brown sugar ADVERTISEMENT', '...   \n",
      "3  ['1 cup butter, softened ADVERTISEMENT', '1 cu...   \n",
      "4  ['8 ounces whole wheat rotini pasta ADVERTISEM...   \n",
      "\n",
      "                                        instructions  \\\n",
      "0  Place the chicken, butter, soup, and onion in ...   \n",
      "1  In a slow cooker, mix cream of mushroom soup, ...   \n",
      "2  Preheat oven to 350 degrees F (175 degrees C)....   \n",
      "3  Preheat oven to 350 degrees F (175 degrees C)....   \n",
      "4  Preheat oven to 350 degrees F. Line a 2-quart ...   \n",
      "\n",
      "                                   ingredients_query      cuisine  \n",
      "0   skinless boneless chicken breast half butter ...  southern_us  \n",
      "1   can condensed cream mushroom soup package dry...  southern_us  \n",
      "2   packed brown sugar ketchup lean ground beef m...  southern_us  \n",
      "3   butter softened white sugar packed brown suga...      italian  \n",
      "4   whole wheat rotini pasta fresh broccoli flore...      italian  \n",
      "(124647, 5)\n"
     ]
    }
   ],
   "source": [
    "create_and_populate_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_db(cuisine):\n",
    "    db = sq.connect('recipes.db')\n",
    "    sql_query = \"SELECT title, instructions, ingredients, ingredients_query FROM main_recipes WHERE cuisine = ?\"\n",
    "    return pd.read_sql(sql_query, db, params = (cuisine, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Doc2Vec function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_embeddings(data): # Recipe dataset\n",
    "    data = data['ingredients_query'].tolist()\n",
    "    tagged_data = [TaggedDocument(words=row.split(), tags=[str(index)]) for index, row in enumerate(data)]\n",
    "\n",
    "    max_epochs = 20\n",
    "    vec_size = 50\n",
    "    alpha = 0.025\n",
    "\n",
    "    model_embedding = Doc2Vec(vector_size=vec_size,\n",
    "                        alpha=alpha, \n",
    "                        min_alpha=0.00025,\n",
    "                        min_count=1,\n",
    "                        dm =1)\n",
    "  \n",
    "    model_embedding.build_vocab(tagged_data)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print('iteration {0}'.format(epoch))\n",
    "        model_embedding.train(tagged_data,\n",
    "                    total_examples=model_embedding.corpus_count,\n",
    "                    epochs=model_embedding.epochs)\n",
    "        # decrease the learning rate\n",
    "        model_embedding.alpha -= 0.0002\n",
    "        # fix the learning rate, no decay\n",
    "        model_embedding.min_alpha = model_embedding.alpha\n",
    "    \n",
    "    return model_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_embeddings():\n",
    "    db = sq.connect('recipes.db')\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    for cuisine in cuisine_classes:\n",
    "        sql_query = \"SELECT title, instructions, ingredients, ingredients_query FROM main_recipes WHERE cuisine = ?\"\n",
    "        data = pd.read_sql(sql_query, db, params=(cuisine,))\n",
    "        \n",
    "        model_embedding = d2v_embeddings(data)\n",
    "        save_pkl(model_embedding, os.path.join(model_embeddings_path, f'd2v_{cuisine}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n"
     ]
    }
   ],
   "source": [
    "train_model_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I dont think we need to run this?\n",
    "\"\"\"\"def infer_cuisine_type_on_recipes(data):\n",
    "    model_path = os.path.join(MODEL_PATH, 'pickle_model.pkl')\n",
    "    model = load_pkl(model_path)\n",
    "    data[\"cuisine\"] = model.predict(data[\"ingredients_query\"])\n",
    "    return data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v. Predict Cuisine function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cuisine(input_text):\n",
    "    top = 5\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text)\n",
    "    \n",
    "    # Get model\n",
    "    model_path = os.path.join(model_path, 'pickle_model.pkl')\n",
    "    model = load_pkl(model_path)\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text)\n",
    "\n",
    "    # Get classes ordered by probability\n",
    "    proba = model.predict_proba([tokenize_text])[0]\n",
    "\n",
    "    # Sorted index list \n",
    "    indexes = sorted(range(len(proba)), key = lambda k: proba[k], reverse=True)\n",
    "\n",
    "    # Get cuisine\n",
    "    cuisine_labels = model.classes_.tolist()\n",
    "    cusine_ordered = [cuisine_labels[ind] for ind in indexes]\n",
    "\n",
    "    return cusine_ordered[: top]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vi. Getting similar recipes function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_recipes(input_text, cuisine, top_k = 3):\n",
    "    # Tokenize text\n",
    "    tokenize_text = get_tokenize_text(input_text).split()\n",
    "    \n",
    "    # Load model from the selected cuisine\n",
    "    d2v = load_pkl(os.path.join(model_embeddings_path, f'd2v_{cuisine}.pkl'))\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = d2v.infer_vector(tokenize_text)\n",
    "    best_recipes = d2v.docvecs.most_similar([embeddings]) #gives you top 10 document tags and their cosine similarity\n",
    "\n",
    "    # Get recipes\n",
    "    best_recipes_index = [int(output[0]) for output in best_recipes]\n",
    "    \n",
    "    # Get dDtaFrame\n",
    "    df = get_df_from_db(cuisine)\n",
    "    \n",
    "    return df[df.index.isin(best_recipes_index)].head(top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Link from Kaggle: https://www.kaggle.com/code/rahulsridhar2811/cuisine-classification-with-accuracy-78-88/notebook\n",
    "#### Additional:\n",
    "\n",
    "* https://htmlpreview.github.io/?https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/blob/master/AWS-lambda-implementation/model_implementation/recipe_binary_classification/recipe%20binary%20classification.html#Naive-Bayes\n",
    "* https://htmlpreview.github.io/?https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/blob/master/AWS-lambda-implementation/model_implementation/recipe_multiclass_classification/recipe%20multiclass%20classification.html#Logistic-Regression\n",
    "* https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/tree/master/AWS-lambda-implementation/model_implementation/recipe_multiclass_classification  \n",
    "\n",
    "\n",
    "* https://github.com/RomainGratier/recipes-telegram-bot\n",
    "* https://towardsdatascience.com/a-recommendation-engine-that-proposes-recipes-after-taking-photos-of-your-ingredients-de2d314f565d?source=friends_link&sk=c5280f8c50aa5551d1b36619891e9b4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5db968608ecdb27000edf98c5f63e9ccc25d479a7a16895421f990979c50088b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
