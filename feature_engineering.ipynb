{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-processing\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, model_selection, pipeline, manifold, preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#feature engg\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import feature_extraction, model_selection, pipeline\n",
    "\n",
    "#to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Cuisine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>29109</td>\n",
       "      <td>irish</td>\n",
       "      <td>[light brown sugar, granulated sugar, butter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>11462</td>\n",
       "      <td>italian</td>\n",
       "      <td>[KRAFT Zesty Italian Dressing, purple onion, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>2238</td>\n",
       "      <td>irish</td>\n",
       "      <td>[eggs, citrus fruit, raisins, sourdough starte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39772</th>\n",
       "      <td>41882</td>\n",
       "      <td>chinese</td>\n",
       "      <td>[boneless chicken skinless thigh, minced garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>2362</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[green chile, jalapeno chilies, onions, ground...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39774 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      cuisine                                        ingredients\n",
       "0      10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1      25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2      20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3      22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4      13162       indian  [black pepper, shallots, cornflour, cayenne pe...\n",
       "...      ...          ...                                                ...\n",
       "39769  29109        irish  [light brown sugar, granulated sugar, butter, ...\n",
       "39770  11462      italian  [KRAFT Zesty Italian Dressing, purple onion, b...\n",
       "39771   2238        irish  [eggs, citrus fruit, raisins, sourdough starte...\n",
       "39772  41882      chinese  [boneless chicken skinless thigh, minced garli...\n",
       "39773   2362      mexican  [green chile, jalapeno chilies, onions, ground...\n",
       "\n",
       "[39774 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuisine = pd.read_json('./data/train.json')\n",
    "display(cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39774 entries, 0 to 39773\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           39774 non-null  int64 \n",
      " 1   cuisine      39774 non-null  object\n",
      " 2   ingredients  39774 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 932.3+ KB\n"
     ]
    }
   ],
   "source": [
    "cuisine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Recipe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_recipes = pd.read_json('./data/recipes_raw_nosource_allrecipes.json', orient='index')\n",
    "epicurious = pd.read_json('./data/recipes_raw_nosource_epicurious.json', orient='index')\n",
    "food_network = pd.read_json('./data/recipes_raw_nosource_foodnetwork.json', orient='index')\n",
    "recipes = pd.concat([all_recipes, epicurious, food_network], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slow Cooker Chicken and Dumplings</td>\n",
       "      <td>[4 skinless, boneless chicken breast halves AD...</td>\n",
       "      <td>Place the chicken, butter, soup, and onion in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Awesome Slow Cooker Pot Roast</td>\n",
       "      <td>[2 (10.75 ounce) cans condensed cream of mushr...</td>\n",
       "      <td>In a slow cooker, mix cream of mushroom soup, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown Sugar Meatloaf</td>\n",
       "      <td>[1/2 cup packed brown sugar ADVERTISEMENT, 1/2...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Chocolate Chip Cookies</td>\n",
       "      <td>[1 cup butter, softened ADVERTISEMENT, 1 cup w...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homemade Mac and Cheese Casserole</td>\n",
       "      <td>[8 ounces whole wheat rotini pasta ADVERTISEME...</td>\n",
       "      <td>Preheat oven to 350 degrees F. Line a 2-quart ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124642</th>\n",
       "      <td>Summer Corn Salad</td>\n",
       "      <td>[4 ears fresh corn, 2 heads Belgian endive, 2 ...</td>\n",
       "      <td>Watch how to make this recipe.\\nPreheat a gril...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124643</th>\n",
       "      <td>Zucchini Stuffed Tomatoes</td>\n",
       "      <td>[4 large plum tomatoes, Salt and sugar, 1 1/2 ...</td>\n",
       "      <td>Preheat the broiler. Cut the tomatoes in 1/2 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124644</th>\n",
       "      <td>Pepper Pasta Quick Cook</td>\n",
       "      <td>[3 tablespoons olive oil, 2 tablespoons unsalt...</td>\n",
       "      <td>Heat the oil and butter in a large skillet ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124645</th>\n",
       "      <td>Chocolate Cake with Armagnac Ice Cream</td>\n",
       "      <td>[8 ounces butter, 8 ounces bittersweet chocola...</td>\n",
       "      <td>Preheat oven to 350 degrees. On the top half o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124646</th>\n",
       "      <td>Crabby Bisque</td>\n",
       "      <td>[3 (10.5-ounce) cans restaurant-style condense...</td>\n",
       "      <td>Watch how to make this recipe.\\nIn a medium sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124647 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0            Slow Cooker Chicken and Dumplings   \n",
       "1                Awesome Slow Cooker Pot Roast   \n",
       "2                         Brown Sugar Meatloaf   \n",
       "3                  Best Chocolate Chip Cookies   \n",
       "4            Homemade Mac and Cheese Casserole   \n",
       "...                                        ...   \n",
       "124642                       Summer Corn Salad   \n",
       "124643               Zucchini Stuffed Tomatoes   \n",
       "124644                 Pepper Pasta Quick Cook   \n",
       "124645  Chocolate Cake with Armagnac Ice Cream   \n",
       "124646                           Crabby Bisque   \n",
       "\n",
       "                                              ingredients  \\\n",
       "0       [4 skinless, boneless chicken breast halves AD...   \n",
       "1       [2 (10.75 ounce) cans condensed cream of mushr...   \n",
       "2       [1/2 cup packed brown sugar ADVERTISEMENT, 1/2...   \n",
       "3       [1 cup butter, softened ADVERTISEMENT, 1 cup w...   \n",
       "4       [8 ounces whole wheat rotini pasta ADVERTISEME...   \n",
       "...                                                   ...   \n",
       "124642  [4 ears fresh corn, 2 heads Belgian endive, 2 ...   \n",
       "124643  [4 large plum tomatoes, Salt and sugar, 1 1/2 ...   \n",
       "124644  [3 tablespoons olive oil, 2 tablespoons unsalt...   \n",
       "124645  [8 ounces butter, 8 ounces bittersweet chocola...   \n",
       "124646  [3 (10.5-ounce) cans restaurant-style condense...   \n",
       "\n",
       "                                             instructions  \n",
       "0       Place the chicken, butter, soup, and onion in ...  \n",
       "1       In a slow cooker, mix cream of mushroom soup, ...  \n",
       "2       Preheat oven to 350 degrees F (175 degrees C)....  \n",
       "3       Preheat oven to 350 degrees F (175 degrees C)....  \n",
       "4       Preheat oven to 350 degrees F. Line a 2-quart ...  \n",
       "...                                                   ...  \n",
       "124642  Watch how to make this recipe.\\nPreheat a gril...  \n",
       "124643  Preheat the broiler. Cut the tomatoes in 1/2 c...  \n",
       "124644  Heat the oil and butter in a large skillet ove...  \n",
       "124645  Preheat oven to 350 degrees. On the top half o...  \n",
       "124646  Watch how to make this recipe.\\nIn a medium sa...  \n",
       "\n",
       "[124647 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recipes = recipes.reset_index()\n",
    "recipes = recipes.drop(columns=['index', 'picture_link'])\n",
    "display(recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words(\"english\")\n",
    "addl_stop_words = ['advertisement', 'advertisments', 'cup', 'cups', 'tablespoon', 'tablespoons', 'teaspoon', 'teaspoons', 'ounce', 'ounces', 'salt', 'pepper', 'pound', 'pounds']\n",
    "stopword_list.extend(addl_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(list, lemmatize = True, stemming = False):\n",
    "    str = ' '.join(list) #converting the list to string\n",
    "    clean_text = ''\n",
    "    \n",
    "    lower = str.lower().split() #lowercase and tokenize\n",
    "    \n",
    "    clean_words = []\n",
    "    for word in lower:\n",
    "        if len(word) > 2:\n",
    "            digit = re.sub(r'\\d+','', word) #removing digits\n",
    "            text = re.sub(r'[^\\w\\s]', '', digit) #removing punc and characters\n",
    "            \n",
    "            \n",
    "            if lemmatize:\n",
    "                lm = WordNetLemmatizer()  #lemmatize\n",
    "                lemm = lm.lemmatize(text)\n",
    "                clean_words.append(lemm)\n",
    "                \n",
    "                if stemming:\n",
    "                    stemmer = PorterStemmer #stemming\n",
    "                    stemm = stemmer.stem(text)\n",
    "                    clean_words.append(stemm)\n",
    "         \n",
    "    rem_stop = [i for i in clean_words if i not in stopword_list]  #remove stopwords\n",
    "    \n",
    "    clean_text = ' '.join(rem_stop) #join as a string\n",
    "    space = re.sub(' +', ' ', clean_text) #remove multi-spaces\n",
    "    \n",
    "    return space    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Ingredients for Recipes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes['clean_ingredients_r'] = recipes['ingredients'].apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>clean_ingredients_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Slow Cooker Chicken and Dumplings</td>\n",
       "      <td>[4 skinless, boneless chicken breast halves AD...</td>\n",
       "      <td>Place the chicken, butter, soup, and onion in ...</td>\n",
       "      <td>skinless boneless chicken breast half butter c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Awesome Slow Cooker Pot Roast</td>\n",
       "      <td>[2 (10.75 ounce) cans condensed cream of mushr...</td>\n",
       "      <td>In a slow cooker, mix cream of mushroom soup, ...</td>\n",
       "      <td>condensed cream mushroom soup package dry oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brown Sugar Meatloaf</td>\n",
       "      <td>[1/2 cup packed brown sugar ADVERTISEMENT, 1/2...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "      <td>packed brown sugar ketchup lean ground beef m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Chocolate Chip Cookies</td>\n",
       "      <td>[1 cup butter, softened ADVERTISEMENT, 1 cup w...</td>\n",
       "      <td>Preheat oven to 350 degrees F (175 degrees C)....</td>\n",
       "      <td>butter softened white sugar packed brown sugar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homemade Mac and Cheese Casserole</td>\n",
       "      <td>[8 ounces whole wheat rotini pasta ADVERTISEME...</td>\n",
       "      <td>Preheat oven to 350 degrees F. Line a 2-quart ...</td>\n",
       "      <td>whole wheat rotini pasta fresh broccoli floret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124642</th>\n",
       "      <td>Summer Corn Salad</td>\n",
       "      <td>[4 ears fresh corn, 2 heads Belgian endive, 2 ...</td>\n",
       "      <td>Watch how to make this recipe.\\nPreheat a gril...</td>\n",
       "      <td>ear fresh corn head belgian endive olive oil f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124643</th>\n",
       "      <td>Zucchini Stuffed Tomatoes</td>\n",
       "      <td>[4 large plum tomatoes, Salt and sugar, 1 1/2 ...</td>\n",
       "      <td>Preheat the broiler. Cut the tomatoes in 1/2 c...</td>\n",
       "      <td>large plum tomato sugar zucchini shallot slice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124644</th>\n",
       "      <td>Pepper Pasta Quick Cook</td>\n",
       "      <td>[3 tablespoons olive oil, 2 tablespoons unsalt...</td>\n",
       "      <td>Heat the oil and butter in a large skillet ove...</td>\n",
       "      <td>olive oil unsalted butter medium clove garlic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124645</th>\n",
       "      <td>Chocolate Cake with Armagnac Ice Cream</td>\n",
       "      <td>[8 ounces butter, 8 ounces bittersweet chocola...</td>\n",
       "      <td>Preheat oven to 350 degrees. On the top half o...</td>\n",
       "      <td>butter bittersweet chocolate whole egg egg yol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124646</th>\n",
       "      <td>Crabby Bisque</td>\n",
       "      <td>[3 (10.5-ounce) cans restaurant-style condense...</td>\n",
       "      <td>Watch how to make this recipe.\\nIn a medium sa...</td>\n",
       "      <td>restaurantstyle condensed crab bisque recommen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124647 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title  \\\n",
       "0            Slow Cooker Chicken and Dumplings   \n",
       "1                Awesome Slow Cooker Pot Roast   \n",
       "2                         Brown Sugar Meatloaf   \n",
       "3                  Best Chocolate Chip Cookies   \n",
       "4            Homemade Mac and Cheese Casserole   \n",
       "...                                        ...   \n",
       "124642                       Summer Corn Salad   \n",
       "124643               Zucchini Stuffed Tomatoes   \n",
       "124644                 Pepper Pasta Quick Cook   \n",
       "124645  Chocolate Cake with Armagnac Ice Cream   \n",
       "124646                           Crabby Bisque   \n",
       "\n",
       "                                              ingredients  \\\n",
       "0       [4 skinless, boneless chicken breast halves AD...   \n",
       "1       [2 (10.75 ounce) cans condensed cream of mushr...   \n",
       "2       [1/2 cup packed brown sugar ADVERTISEMENT, 1/2...   \n",
       "3       [1 cup butter, softened ADVERTISEMENT, 1 cup w...   \n",
       "4       [8 ounces whole wheat rotini pasta ADVERTISEME...   \n",
       "...                                                   ...   \n",
       "124642  [4 ears fresh corn, 2 heads Belgian endive, 2 ...   \n",
       "124643  [4 large plum tomatoes, Salt and sugar, 1 1/2 ...   \n",
       "124644  [3 tablespoons olive oil, 2 tablespoons unsalt...   \n",
       "124645  [8 ounces butter, 8 ounces bittersweet chocola...   \n",
       "124646  [3 (10.5-ounce) cans restaurant-style condense...   \n",
       "\n",
       "                                             instructions  \\\n",
       "0       Place the chicken, butter, soup, and onion in ...   \n",
       "1       In a slow cooker, mix cream of mushroom soup, ...   \n",
       "2       Preheat oven to 350 degrees F (175 degrees C)....   \n",
       "3       Preheat oven to 350 degrees F (175 degrees C)....   \n",
       "4       Preheat oven to 350 degrees F. Line a 2-quart ...   \n",
       "...                                                   ...   \n",
       "124642  Watch how to make this recipe.\\nPreheat a gril...   \n",
       "124643  Preheat the broiler. Cut the tomatoes in 1/2 c...   \n",
       "124644  Heat the oil and butter in a large skillet ove...   \n",
       "124645  Preheat oven to 350 degrees. On the top half o...   \n",
       "124646  Watch how to make this recipe.\\nIn a medium sa...   \n",
       "\n",
       "                                      clean_ingredients_r  \n",
       "0       skinless boneless chicken breast half butter c...  \n",
       "1        condensed cream mushroom soup package dry oni...  \n",
       "2        packed brown sugar ketchup lean ground beef m...  \n",
       "3       butter softened white sugar packed brown sugar...  \n",
       "4       whole wheat rotini pasta fresh broccoli floret...  \n",
       "...                                                   ...  \n",
       "124642  ear fresh corn head belgian endive olive oil f...  \n",
       "124643  large plum tomato sugar zucchini shallot slice...  \n",
       "124644  olive oil unsalted butter medium clove garlic ...  \n",
       "124645  butter bittersweet chocolate whole egg egg yol...  \n",
       "124646  restaurantstyle condensed crab bisque recommen...  \n",
       "\n",
       "[124647 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before and After Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 (32 ounce) package frozen hash brown potatoes ADVERTISEMENT', '8 ounces cooked, diced ham ADVERTISEMENT', '2 (10.75 ounce) cans condensed cream of potato soup ADVERTISEMENT', '1 (16 ounce) container sour cream ADVERTISEMENT', '2 cups shredded sharp Cheddar cheese ADVERTISEMENT', '1 1/2 cups grated Parmesan cheese ADVERTISEMENT', 'ADVERTISEMENT']\n",
      "\n",
      "\n",
      " package frozen hash brown potato cooked diced ham condensed cream potato soup container sour cream shredded sharp cheddar cheese grated parmesan cheese\n"
     ]
    }
   ],
   "source": [
    "print(recipes['ingredients'][200])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(recipes['clean_ingredients_r'][200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Removing NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 124647 entries, 0 to 124646\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   title                124595 non-null  object\n",
      " 1   ingredients          124647 non-null  object\n",
      " 2   instructions         124473 non-null  object\n",
      " 3   clean_ingredients_r  124647 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#dataframe info\n",
    "\n",
    "recipes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing NA\n",
    "\n",
    "recipes.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 124473 entries, 0 to 124646\n",
      "Data columns (total 4 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   title                124473 non-null  object\n",
      " 1   ingredients          124473 non-null  object\n",
      " 2   instructions         124473 non-null  object\n",
      " 3   clean_ingredients_r  124473 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#after removing NA\n",
    "\n",
    "recipes.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Ingredients for Cuisine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>29109</td>\n",
       "      <td>irish</td>\n",
       "      <td>[light brown sugar, granulated sugar, butter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>11462</td>\n",
       "      <td>italian</td>\n",
       "      <td>[KRAFT Zesty Italian Dressing, purple onion, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>2238</td>\n",
       "      <td>irish</td>\n",
       "      <td>[eggs, citrus fruit, raisins, sourdough starte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39772</th>\n",
       "      <td>41882</td>\n",
       "      <td>chinese</td>\n",
       "      <td>[boneless chicken skinless thigh, minced garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>2362</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[green chile, jalapeno chilies, onions, ground...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39774 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      cuisine                                        ingredients\n",
       "0      10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1      25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2      20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3      22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4      13162       indian  [black pepper, shallots, cornflour, cayenne pe...\n",
       "...      ...          ...                                                ...\n",
       "39769  29109        irish  [light brown sugar, granulated sugar, butter, ...\n",
       "39770  11462      italian  [KRAFT Zesty Italian Dressing, purple onion, b...\n",
       "39771   2238        irish  [eggs, citrus fruit, raisins, sourdough starte...\n",
       "39772  41882      chinese  [boneless chicken skinless thigh, minced garli...\n",
       "39773   2362      mexican  [green chile, jalapeno chilies, onions, ground...\n",
       "\n",
       "[39774 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine['clean_ingredients_c'] = cuisine['ingredients'].apply(lambda x: clean_string(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['turnip greens', 'vegetable oil', 'fresh lemon juice', 'black peppercorns', 'butternut squash', 'apples', 'kosher salt', 'buttermilk', 'country ham', 'shallots', 'extra-virgin olive oil']\n",
      "\n",
      "\n",
      "turnip green vegetable oil fresh lemon juice black peppercorn butternut squash apple kosher buttermilk country ham shallot extravirgin olive oil\n"
     ]
    }
   ],
   "source": [
    "print(cuisine['ingredients'][200])\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print(cuisine['clean_ingredients_c'][200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engg and Classification of Cuisines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_uni = CountVectorizer(lowercase = True, stop_words = 'english', ngram_range = (1,1))\n",
    "count_bi = CountVectorizer(lowercase = True,stop_words = 'english', ngram_range = (1,2))\n",
    "count_binary = CountVectorizer(lowercase = True,stop_words = 'english', ngram_range = (1,2), binary = True)\n",
    "tfidf_uni = TfidfVectorizer(lowercase = True,stop_words = 'english', ngram_range = (1,1))\n",
    "tfidf_bi = TfidfVectorizer(lowercase = True,stop_words = 'english', ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_dict = {'count_uni': count_uni,\n",
    "            'count_bi': count_bi,\n",
    "            'count_binary': count_binary,\n",
    "            'tfidf_uni': tfidf_uni,\n",
    "            'tfidf_bi': tfidf_bi}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsetting dataset for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>clean_ingredients_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>romaine lettuce black olive grape tomato garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>plain flour ground tomato ground black thyme e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>egg mayonaise cooking oil green chilies grille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>water vegetable oil wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>black shallot cornflour cayenne onion garlic p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5964</td>\n",
       "      <td>italian</td>\n",
       "      <td>[tomato sauce, extra-virgin olive oil, grated ...</td>\n",
       "      <td>tomato sauce extravirgin olive oil grated parm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>30297</td>\n",
       "      <td>korean</td>\n",
       "      <td>[water, medium-grain rice]</td>\n",
       "      <td>water mediumgrain rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>3037</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[eggs, grating cheese, jalapeno chilies, fresh...</td>\n",
       "      <td>egg grating cheese jalapeno chilies freshly gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>19712</td>\n",
       "      <td>cajun_creole</td>\n",
       "      <td>[andouille sausage, butter, garlic cloves, dri...</td>\n",
       "      <td>andouille sausage butter garlic clove dried or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>4400</td>\n",
       "      <td>greek</td>\n",
       "      <td>[ground black pepper, extra-virgin olive oil, ...</td>\n",
       "      <td>ground black extravirgin olive oil fresh orega...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       cuisine                                        ingredients  \\\n",
       "0    10259         greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1    25693   southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2    20130      filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3    22213        indian                [water, vegetable oil, wheat, salt]   \n",
       "4    13162        indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "..     ...           ...                                                ...   \n",
       "995   5964       italian  [tomato sauce, extra-virgin olive oil, grated ...   \n",
       "996  30297        korean                         [water, medium-grain rice]   \n",
       "997   3037       mexican  [eggs, grating cheese, jalapeno chilies, fresh...   \n",
       "998  19712  cajun_creole  [andouille sausage, butter, garlic cloves, dri...   \n",
       "999   4400         greek  [ground black pepper, extra-virgin olive oil, ...   \n",
       "\n",
       "                                   clean_ingredients_c  \n",
       "0    romaine lettuce black olive grape tomato garli...  \n",
       "1    plain flour ground tomato ground black thyme e...  \n",
       "2    egg mayonaise cooking oil green chilies grille...  \n",
       "3                            water vegetable oil wheat  \n",
       "4    black shallot cornflour cayenne onion garlic p...  \n",
       "..                                                 ...  \n",
       "995  tomato sauce extravirgin olive oil grated parm...  \n",
       "996                             water mediumgrain rice  \n",
       "997  egg grating cheese jalapeno chilies freshly gr...  \n",
       "998  andouille sausage butter garlic clove dried or...  \n",
       "999  ground black extravirgin olive oil fresh orega...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuisine_subset = cuisine.head(n = 1000)\n",
    "display(cuisine_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "italian         7838\n",
       "mexican         6438\n",
       "southern_us     4320\n",
       "indian          3003\n",
       "chinese         2673\n",
       "french          2646\n",
       "cajun_creole    1546\n",
       "thai            1539\n",
       "japanese        1423\n",
       "greek           1175\n",
       "spanish          989\n",
       "korean           830\n",
       "vietnamese       825\n",
       "moroccan         821\n",
       "british          804\n",
       "filipino         755\n",
       "irish            667\n",
       "jamaican         526\n",
       "russian          489\n",
       "brazilian        467\n",
       "Name: cuisine, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuisine.cuisine.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression, SVM, Random Forest, Naive Bayes,  Neural Networks, KNN\n",
    " \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import feature_extraction, model_selection, pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import NMF, PCA, TruncatedSVD, FastICA\n",
    "from sklearn.model_selection import cross_validate, KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Classifier with Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseToDense(TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y = None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None, **fit_params):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "ncomps = [5, 10, 20, 50, 75, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cuisine['clean_ingredients_c']\n",
    "y = cuisine['cuisine']\n",
    "\n",
    "##X_count = tfidf_uni.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        romaine lettuce black olive grape tomato garli...\n",
       "1        plain flour ground tomato ground black thyme e...\n",
       "2        egg mayonaise cooking oil green chilies grille...\n",
       "3                                water vegetable oil wheat\n",
       "4        black shallot cornflour cayenne onion garlic p...\n",
       "                               ...                        \n",
       "39769    light brown sugar granulated sugar butter warm...\n",
       "39770    kraft zesty italian dressing purple onion broc...\n",
       "39771    egg citrus fruit raisin sourdough starter flou...\n",
       "39772    boneless chicken skinless thigh minced garlic ...\n",
       "39773    green chile jalapeno chilies onion ground blac...\n",
       "Name: clean_ingredients_c, Length: 39774, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_subset_map={'0':'brazilian', '1':'british', '2':'cajun_creole', '3':'chinese', '4':'filipino', '5':'french', '6':'greek', '7':'indian', '8':'irish', '9':'italian', '10':'jamaican', '11':'japanese', '12':'korean', '13':'mexican', '14':'moroccan', '15':'russian', '16':'southern_us', '17':'spanish', '18':'thai', '19':'vietnamese'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross Validation\n",
    "#outer loop should be smaller\n",
    "#Fraction of the whole dataset (1/2 of dataset) -- startified sampling to select same amt of data from each category\n",
    "#shrink the dataset to half\n",
    "#print intermediate results\n",
    "#reduce hyper params tuning\n",
    "#reduce dataset, verboase = 10; estimate how long it takes \n",
    "#BERT for feature extraction\n",
    "#https://www.tensorflow.org/text/tutorials/classify_text_with_bert\n",
    "\n",
    "\n",
    "inner_cv = KFold(n_splits = 2, shuffle = True, random_state = 1)\n",
    "outer_cv = KFold(n_splits = 3, shuffle = True, random_state = 1) #decreasing this number might help\n",
    "\n",
    "#Stating the parameters\n",
    "\n",
    "kernel = ['rbf', 'radial', 'poly'] # \n",
    "C = [1, 10, 100, 1000]\n",
    "\n",
    "# set up parameter grid\n",
    "params = {'classify__kernel': kernel, 'classify__C': C}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for method in vect_dict:\n",
    "        pipe = Pipeline([\n",
    "        ('vectorize',  vect_dict[method]),\n",
    "        ('densify', SparseToDense()),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('dim_red', pca),\n",
    "        ('classify', svc)])\n",
    "        \n",
    "        grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, verbose = 10) #verbose = 10\n",
    "        \n",
    "        scores = cross_validate(grid_SVC,\n",
    "                       X = X,\n",
    "                       y = y,\n",
    "                       cv = outer_cv, \n",
    "                       scoring = {'accuracy' : make_scorer(accuracy_score),\n",
    "       'precision' : make_scorer(precision_score, average = 'macro'),\n",
    "       'recall' : make_scorer(recall_score, average = 'macro'), \n",
    "       'f1_score' : make_scorer(f1_score, average = 'macro')},\n",
    "                       return_estimator = True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 12 candidates, totalling 24 fits\n",
      "[CV 1/2; 1/12] START classify__C=1, classify__kernel=rbf........................\n"
     ]
    }
   ],
   "source": [
    " pipe = Pipeline([('vectorize', tfidf_bi),\n",
    "        ('densify', SparseToDense()),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('dim_red', pca),\n",
    "        ('classify', svc)])\n",
    "        \n",
    "grid_SVC = GridSearchCV(pipe, params, cv = inner_cv, verbose = 10) #verbose = 10\n",
    "        \n",
    "scores = cross_validate(grid_SVC,\n",
    "                       X = X,\n",
    "                       y = y,\n",
    "                       cv = outer_cv, \n",
    "                       scoring = {'accuracy' : make_scorer(accuracy_score),\n",
    "       'precision' : make_scorer(precision_score, average = 'macro'),\n",
    "       'recall' : make_scorer(recall_score, average = 'macro'), \n",
    "       'f1_score' : make_scorer(f1_score, average = 'macro')},\n",
    "                       return_estimator = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23884531 0.23975532 0.2664474 ]\n",
      "[0.23328955 0.23244513 0.25525637]\n",
      "[0.39990993 0.36994563 0.42246204]\n",
      "[0.50299401 0.52852853 0.56756757]\n"
     ]
    }
   ],
   "source": [
    "print(list(scores.values())[-1])\n",
    "print(list(scores.values())[-2])\n",
    "print(list(scores.values())[-3])\n",
    "print(list(scores.values())[-4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for AUC (To revisit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def custom_auc(ground_truth, predictions):\n",
    "  \n",
    "     fpr, tpr, _ = roc_curve(ground_truth, predictions[:, 1], pos_label=1)    \n",
    "     return auc(fpr, tpr)\n",
    "\n",
    "# to be standart sklearn's scorer        \n",
    " my_auc = make_scorer(custom_auc, greater_is_better=True, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Link from Kaggle: https://www.kaggle.com/code/rahulsridhar2811/cuisine-classification-with-accuracy-78-88/notebook\n",
    "#### Additional:\n",
    "\n",
    "* https://htmlpreview.github.io/?https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/blob/master/AWS-lambda-implementation/model_implementation/recipe_binary_classification/recipe%20binary%20classification.html#Naive-Bayes\n",
    "* https://htmlpreview.github.io/?https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/blob/master/AWS-lambda-implementation/model_implementation/recipe_multiclass_classification/recipe%20multiclass%20classification.html#Logistic-Regression\n",
    "* https://github.com/kulsoom-abdullah/kulsoom-abdullah.github.io/tree/master/AWS-lambda-implementation/model_implementation/recipe_multiclass_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split, cross_validate,StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_subset = cuisine.sample(n = 17000)\n",
    "#display(cuisine_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_s = cuisine_subset['clean_ingredients_c']\n",
    "y_s = cuisine_subset['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuisine full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cuisine['clean_ingredients_c']\n",
    "y = cuisine['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Vectorizer and Test_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TFIDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "\n",
    "#Using stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify = y, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 300, random_state = 123, multi_class = 'multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 10\n",
      "Best Solver: newton-cg\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "penalty = ['l2', 'l1', 'elasticnet']\n",
    "C = [0.001, 0.01, 0.1, 10]\n",
    "solvers = ['newton-cg', 'lbfgs']\n",
    "\n",
    "#Fitting into pipeline\n",
    "lr_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('lr', lr)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(lr__C = C, lr__penalty = penalty, lr__solver = solvers)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(lr_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['lr__penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['lr__C'])\n",
    "print('Best Solver:', best_model.best_estimator_.get_params()['lr__solver'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logistic Regression  - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7835361766450769\n",
      "Accuracy score 0.7874094931617055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.80      0.57      0.67       117\n",
      "     british       0.62      0.45      0.52       201\n",
      "cajun_creole       0.78      0.69      0.73       386\n",
      "     chinese       0.81      0.87      0.84       668\n",
      "    filipino       0.79      0.56      0.65       189\n",
      "      french       0.58      0.67      0.62       662\n",
      "       greek       0.77      0.69      0.73       294\n",
      "      indian       0.87      0.91      0.89       751\n",
      "       irish       0.69      0.49      0.58       167\n",
      "     italian       0.81      0.89      0.84      1960\n",
      "    jamaican       0.92      0.72      0.81       131\n",
      "    japanese       0.85      0.69      0.76       356\n",
      "      korean       0.86      0.75      0.80       207\n",
      "     mexican       0.91      0.91      0.91      1610\n",
      "    moroccan       0.81      0.77      0.79       205\n",
      "     russian       0.65      0.44      0.53       122\n",
      " southern_us       0.72      0.81      0.76      1080\n",
      "     spanish       0.61      0.47      0.53       247\n",
      "        thai       0.74      0.81      0.77       385\n",
      "  vietnamese       0.68      0.48      0.56       206\n",
      "\n",
      "    accuracy                           0.79      9944\n",
      "   macro avg       0.76      0.68      0.71      9944\n",
      "weighted avg       0.79      0.79      0.78      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train_lr = vectorizer.fit_transform(X_train)\n",
    "matrix_test_lr = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "lr_final = LogisticRegression(max_iter = 300, random_state = 123, multi_class ='multinomial', solver = 'newton-cg', C = 10, penalty = 'l2')\n",
    "lr_final.fit(matrix_train_lr, y_train)\n",
    "y_pred = lr_final.predict(matrix_test_lr)\n",
    "pred_prob = lr_final.predict_proba(matrix_test_lr)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, pred_prob))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "#cm_lr_test=confusion_matrix(y_test, y_pred)\n",
    "#print(cm_lr_test)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred)\n",
    "f1_lr = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Multinomial Naive Bayes - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha: 0.01\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params\n",
    "alpha = [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "\n",
    "#Fitting into pipeline\n",
    "nb_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('nb', nb)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(nb__alpha = alpha)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(nb_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Alpha:', best_model.best_estimator_.get_params()['nb__alpha'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7366113370242328\n",
      "Accuracy score 0.7417538213998391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.71      0.47      0.57       117\n",
      "     british       0.53      0.41      0.46       201\n",
      "cajun_creole       0.66      0.69      0.68       386\n",
      "     chinese       0.76      0.88      0.81       668\n",
      "    filipino       0.80      0.49      0.61       189\n",
      "      french       0.52      0.60      0.56       662\n",
      "       greek       0.74      0.56      0.64       294\n",
      "      indian       0.84      0.88      0.86       751\n",
      "       irish       0.71      0.44      0.54       167\n",
      "     italian       0.78      0.85      0.81      1960\n",
      "    jamaican       0.85      0.58      0.69       131\n",
      "    japanese       0.85      0.64      0.73       356\n",
      "      korean       0.88      0.65      0.75       207\n",
      "     mexican       0.88      0.88      0.88      1610\n",
      "    moroccan       0.76      0.70      0.73       205\n",
      "     russian       0.66      0.34      0.45       122\n",
      " southern_us       0.63      0.75      0.68      1080\n",
      "     spanish       0.58      0.37      0.45       247\n",
      "        thai       0.66      0.78      0.72       385\n",
      "  vietnamese       0.64      0.44      0.52       206\n",
      "\n",
      "    accuracy                           0.74      9944\n",
      "   macro avg       0.72      0.62      0.66      9944\n",
      "weighted avg       0.74      0.74      0.74      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "nb_final = MultinomialNB(alpha = 0.01)\n",
    "nb_final.fit(matrix_train, y_train)\n",
    "y_pred = nb_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average ='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_mnb = accuracy_score(y_test, y_pred)\n",
    "f1_mnb = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Estimator: 500\n",
      "Best features: sqrt\n",
      "Best samples split: 2\n",
      "Best samples leaf: 5\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "n_estimators = [10, 100, 500]\n",
    "max_features = ['sqrt', 'log2']\n",
    "min_samples_split = [2, 10, 100]\n",
    "min_samples_leaf = [5, 10] \n",
    "\n",
    "\n",
    "#Fitting into pipeline\n",
    "rf_pipe = Pipeline([('vect', vectorizer), \n",
    "                    ('rf', rf)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(rf__n_estimators = estimators, rf__max_features = max_features, rf__min_samples_split = min_samples_split, rf__min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(rf_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X, y)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Estimator:', best_model.best_estimator_.get_params()['rf__n_estimators'])\n",
    "print('Best features:', best_model.best_estimator_.get_params()['rf__max_features'])\n",
    "print('Best samples split:', best_model.best_estimator_.get_params()['rf__min_samples_split'])\n",
    "print('Best samples leaf:', best_model.best_estimator_.get_params()['rf__min_samples_leaf'])\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.5700773806452174\n",
      "Accuracy score 0.6296259050683829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.84      0.26      0.40       117\n",
      "     british       0.00      0.00      0.00       201\n",
      "cajun_creole       0.87      0.48      0.62       386\n",
      "     chinese       0.61      0.90      0.73       668\n",
      "    filipino       1.00      0.06      0.12       189\n",
      "      french       0.57      0.21      0.30       662\n",
      "       greek       0.93      0.22      0.35       294\n",
      "      indian       0.77      0.87      0.82       751\n",
      "       irish       0.80      0.02      0.05       167\n",
      "     italian       0.56      0.92      0.70      1960\n",
      "    jamaican       1.00      0.10      0.18       131\n",
      "    japanese       0.95      0.46      0.62       356\n",
      "      korean       0.98      0.20      0.34       207\n",
      "     mexican       0.74      0.91      0.82      1610\n",
      "    moroccan       1.00      0.18      0.31       205\n",
      "     russian       0.00      0.00      0.00       122\n",
      " southern_us       0.47      0.70      0.56      1080\n",
      "     spanish       0.00      0.00      0.00       247\n",
      "        thai       0.65      0.68      0.67       385\n",
      "  vietnamese       0.74      0.07      0.12       206\n",
      "\n",
      "    accuracy                           0.63      9944\n",
      "   macro avg       0.67      0.36      0.39      9944\n",
      "weighted avg       0.65      0.63      0.57      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train_rf = vectorizer.fit_transform(X_train)\n",
    "matrix_test_rf = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "rf_final = RandomForestClassifier(random_state = 123, n_estimators = 500, max_features = 'sqrt', min_samples_split = 2, min_samples_leaf = 5)\n",
    "rf_final.fit(matrix_train_rf, y_train)\n",
    "y_pred = rf_final.predict(matrix_test_rf)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average ='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred)\n",
    "f1_rf = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC - Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Kernel: sigmoid\n",
      "Best C: 10\n"
     ]
    }
   ],
   "source": [
    "#Assigning values to params \n",
    "kernel = ['rbf', 'poly', 'sigmoid']  \n",
    "C = [0.001, 0.01, 0.1, 10]\n",
    "\n",
    "#Fitting into pipeline\n",
    "svc_pipe = Pipeline([('vect', vectorizer),\n",
    "                      #('densify', SparseToDense()),\n",
    "                      #('scale', StandardScaler()),\n",
    "                      ('svc', svc)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(svc__kernel = kernel, svc__C = C)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(svc_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X_s, y_s)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Kernel:', best_model.best_estimator_.get_params()['svc__kernel'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['svc__C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7517830331203548\n",
      "Accuracy score 0.7522123893805309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.68      0.65      0.66       117\n",
      "     british       0.49      0.53      0.51       201\n",
      "cajun_creole       0.71      0.69      0.70       386\n",
      "     chinese       0.78      0.84      0.81       668\n",
      "    filipino       0.69      0.60      0.64       189\n",
      "      french       0.50      0.64      0.56       662\n",
      "       greek       0.68      0.69      0.69       294\n",
      "      indian       0.85      0.88      0.87       751\n",
      "       irish       0.52      0.47      0.50       167\n",
      "     italian       0.80      0.81      0.81      1960\n",
      "    jamaican       0.85      0.76      0.80       131\n",
      "    japanese       0.76      0.68      0.72       356\n",
      "      korean       0.84      0.74      0.79       207\n",
      "     mexican       0.89      0.89      0.89      1610\n",
      "    moroccan       0.77      0.77      0.77       205\n",
      "     russian       0.56      0.40      0.47       122\n",
      " southern_us       0.73      0.70      0.71      1080\n",
      "     spanish       0.56      0.44      0.50       247\n",
      "        thai       0.77      0.78      0.77       385\n",
      "  vietnamese       0.61      0.49      0.54       206\n",
      "\n",
      "    accuracy                           0.75      9944\n",
      "   macro avg       0.70      0.67      0.69      9944\n",
      "weighted avg       0.75      0.75      0.75      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "svc_final = SVC(random_state = 123, kernel = 'sigmoid', C = 10)\n",
    "svc_final.fit(matrix_train, y_train)\n",
    "y_pred = svc_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred)\n",
    "f1_svm = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB - Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = xgb.XGBClassifier(objective = 'multi:softmax', eval_metric = 'mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth: 1\n",
      "Best Gamma: 1\n",
      "Best Alpha: 1\n",
      "Best Lambda: 0\n",
      "Best Colsample: 0.5\n",
      "Best Child weight: 1\n",
      "Best ETA: 0.5\n"
     ]
    }
   ],
   "source": [
    "max_depth = [1, 5, 20, 50]\n",
    "gamma = [1, 10]\n",
    "reg_alpha = [1, 40, 180]\n",
    "reg_lambda = [0, 1]\n",
    "colsample_bytree = [0.5, 1]\n",
    "min_child_weight = [0, 1, 10]\n",
    "eta = [0.5, 1]\n",
    "\n",
    "\n",
    "xgb_pipe = Pipeline([('vect', vectorizer),\n",
    "                      ('xgb', xgb)])\n",
    "\n",
    "#Create hyperparameter dict\n",
    "hyperparameters = dict(xgb__max_depth = max_depth, xgb__gamma = gamma, xgb__reg_alpha = reg_alpha, \n",
    "                       xgb__reg_lambda = reg_lambda, xgb__colsample_bytree = colsample_bytree, xgb__min_child_weight = min_child_weight, xgb__eta = eta)\n",
    "\n",
    "#Grid search\n",
    "clf = GridSearchCV(xgb_pipe, hyperparameters, cv = 5)\n",
    "best_model = clf.fit(X_s, y_s)\n",
    "\n",
    "#Printing best params\n",
    "print('Best Depth:', best_model.best_estimator_.get_params()['xgb__max_depth'])\n",
    "print('Best Gamma:', best_model.best_estimator_.get_params()['xgb__gamma'])\n",
    "print('Best Alpha:', best_model.best_estimator_.get_params()['xgb__reg_alpha'])\n",
    "print('Best Lambda:', best_model.best_estimator_.get_params()['xgb__reg_lambda'])\n",
    "print('Best Colsample:', best_model.best_estimator_.get_params()['xgb__colsample_bytree'])\n",
    "print('Best Child weight:', best_model.best_estimator_.get_params()['xgb__min_child_weight'])\n",
    "print('Best ETA:', best_model.best_estimator_.get_params()['xgb__eta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score weighted 0.7420894779545216\n",
      "Accuracy score 0.7489943684633951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   brazilian       0.74      0.57      0.64       117\n",
      "     british       0.54      0.23      0.33       201\n",
      "cajun_creole       0.81      0.65      0.72       386\n",
      "     chinese       0.79      0.84      0.81       668\n",
      "    filipino       0.69      0.48      0.56       189\n",
      "      french       0.53      0.56      0.54       662\n",
      "       greek       0.79      0.71      0.75       294\n",
      "      indian       0.87      0.86      0.86       751\n",
      "       irish       0.67      0.44      0.53       167\n",
      "     italian       0.71      0.88      0.78      1960\n",
      "    jamaican       0.89      0.69      0.78       131\n",
      "    japanese       0.87      0.66      0.75       356\n",
      "      korean       0.80      0.67      0.73       207\n",
      "     mexican       0.89      0.90      0.89      1610\n",
      "    moroccan       0.80      0.71      0.75       205\n",
      "     russian       0.57      0.35      0.44       122\n",
      " southern_us       0.66      0.76      0.71      1080\n",
      "     spanish       0.64      0.42      0.51       247\n",
      "        thai       0.74      0.81      0.77       385\n",
      "  vietnamese       0.70      0.40      0.51       206\n",
      "\n",
      "    accuracy                           0.75      9944\n",
      "   macro avg       0.73      0.63      0.67      9944\n",
      "weighted avg       0.75      0.75      0.74      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Fitting vectorizer\n",
    "matrix_train = vectorizer.fit_transform(X_train)\n",
    "matrix_test = vectorizer.transform(X_test)\n",
    "\n",
    "#Fitting final model with Best hyper params\n",
    "xgb_final = xgb.XGBClassifier(objective = 'multi:softmax', max_depth = 1, gamma = 1, reg_alpha = 1, \n",
    "                     reg_lambda = 0, colsample_bytree = 0.5, min_child_weight = 1, eta = 0.5, eval_metric = 'mlogloss')\n",
    "\n",
    "xgb_final.fit(matrix_train, y_train)\n",
    "y_pred = xgb_final.predict(matrix_test)\n",
    "\n",
    "#Classification metrics\n",
    "print('f1 score weighted %s' % f1_score(y_test,y_pred, average='weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred))\n",
    "#print('AUC score %s' % roc_auc_score(y_test, y_pred))\n",
    "#print('ROC score %s' % roc_curve(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred)\n",
    "f1_xgb = f1_score(y_test, y_pred, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over and Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn import pipeline as pl\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_samp = LogisticRegression(max_iter = 300, random_state = 123, multi_class = 'multinomial',  solver = 'newton-cg', C = 10, penalty = 'l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_os = RandomOverSampler(random_state=123)\n",
    "random_us = RandomUnderSampler(random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on oversampling:\n",
      "\n",
      "f1 score weighted 0.7850797931436236\n",
      "Accuracy score 0.7838897827835881\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   brazilian       0.71      0.68      1.00      0.69      0.82      0.65       117\n",
      "     british       0.53      0.57      0.99      0.55      0.75      0.54       201\n",
      "cajun_creole       0.74      0.74      0.99      0.74      0.86      0.72       386\n",
      "     chinese       0.82      0.84      0.99      0.83      0.91      0.82       668\n",
      "    filipino       0.71      0.65      0.99      0.68      0.80      0.62       189\n",
      "      french       0.58      0.68      0.96      0.62      0.81      0.63       662\n",
      "       greek       0.71      0.77      0.99      0.74      0.87      0.74       294\n",
      "      indian       0.89      0.90      0.99      0.89      0.95      0.89       751\n",
      "       irish       0.57      0.57      0.99      0.57      0.75      0.54       167\n",
      "     italian       0.85      0.82      0.96      0.84      0.89      0.78      1960\n",
      "    jamaican       0.83      0.79      1.00      0.81      0.89      0.78       131\n",
      "    japanese       0.83      0.72      0.99      0.77      0.85      0.70       356\n",
      "      korean       0.81      0.79      1.00      0.80      0.89      0.77       207\n",
      "     mexican       0.93      0.90      0.99      0.91      0.94      0.88      1610\n",
      "    moroccan       0.74      0.81      0.99      0.78      0.90      0.79       205\n",
      "     russian       0.55      0.52      0.99      0.54      0.72      0.50       122\n",
      " southern_us       0.76      0.76      0.97      0.76      0.86      0.73      1080\n",
      "     spanish       0.52      0.52      0.99      0.52      0.72      0.49       247\n",
      "        thai       0.74      0.79      0.99      0.77      0.89      0.77       385\n",
      "  vietnamese       0.62      0.54      0.99      0.58      0.73      0.51       206\n",
      "\n",
      " avg / total       0.79      0.78      0.98      0.79      0.87      0.76      9944\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipe_os = pl.make_pipeline(vectorizer,\n",
    "                           random_os,\n",
    "                           lr_samp)\n",
    "\n",
    "\n",
    "# Train the classifier with balancing\n",
    "lr_pipe_os.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = lr_pipe_os.predict(X_test)\n",
    "\n",
    "print(\"results on oversampling:\\n\")\n",
    "\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred_bal, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred_bal))\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "\n",
    "acc_os_lr = accuracy_score(y_test, y_pred_bal)\n",
    "f1_os_lr = f1_score(y_test, y_pred_bal, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results on Undersampling:\n",
      "\n",
      "f1 score weighted 0.7208509660202405\n",
      "Accuracy score 0.705852775543041\n",
      "                    pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "   brazilian       0.42      0.76      0.99      0.54      0.87      0.73       117\n",
      "     british       0.31      0.62      0.97      0.42      0.77      0.58       201\n",
      "cajun_creole       0.63      0.76      0.98      0.69      0.86      0.73       386\n",
      "     chinese       0.85      0.77      0.99      0.81      0.87      0.75       668\n",
      "    filipino       0.49      0.68      0.99      0.57      0.82      0.65       189\n",
      "      french       0.50      0.53      0.96      0.52      0.72      0.49       662\n",
      "       greek       0.60      0.79      0.98      0.68      0.88      0.76       294\n",
      "      indian       0.91      0.83      0.99      0.87      0.91      0.81       751\n",
      "       irish       0.35      0.63      0.98      0.45      0.79      0.59       167\n",
      "     italian       0.89      0.67      0.98      0.76      0.81      0.63      1960\n",
      "    jamaican       0.62      0.83      0.99      0.71      0.91      0.81       131\n",
      "    japanese       0.80      0.67      0.99      0.73      0.82      0.65       356\n",
      "      korean       0.70      0.77      0.99      0.74      0.88      0.75       207\n",
      "     mexican       0.95      0.81      0.99      0.87      0.90      0.79      1610\n",
      "    moroccan       0.60      0.83      0.99      0.70      0.91      0.81       205\n",
      "     russian       0.32      0.67      0.98      0.44      0.81      0.64       122\n",
      " southern_us       0.79      0.58      0.98      0.67      0.75      0.55      1080\n",
      "     spanish       0.34      0.60      0.97      0.43      0.76      0.56       247\n",
      "        thai       0.76      0.73      0.99      0.74      0.85      0.70       385\n",
      "  vietnamese       0.53      0.63      0.99      0.58      0.79      0.60       206\n",
      "\n",
      " avg / total       0.76      0.71      0.98      0.72      0.83      0.68      9944\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_pry_pred_bal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3632/1904008989.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report_imbalanced\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_bal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0macc_us_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pry_pred_bal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mf1_us_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_bal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pry_pred_bal' is not defined"
     ]
    }
   ],
   "source": [
    "lr_pipe_us = pl.make_pipeline(vectorizer,\n",
    "                           random_us,\n",
    "                           lr_samp)\n",
    "\n",
    "\n",
    "\n",
    "# Train the classifier with balancing\n",
    "lr_pipe_us.fit(X_train, y_train)\n",
    "\n",
    "# Test the classifier and get the prediction\n",
    "y_pred_bal = lr_pipe_us.predict(X_test)\n",
    "\n",
    "print(\"results on Undersampling:\\n\")\n",
    "\n",
    "print('f1 score weighted %s' % f1_score(y_test, y_pred_bal, average = 'weighted'))\n",
    "print('Accuracy score %s' % accuracy_score(y_test, y_pred_bal))\n",
    "print(classification_report_imbalanced(y_test, y_pred_bal))\n",
    "\n",
    "acc_us_lr = accuracy_score(y_test, y_pry_pred_bal)\n",
    "f1_us_lr = f1_score(y_test, y_pred_bal, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787409</td>\n",
       "      <td>0.783536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.751783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XG Boost Model</td>\n",
       "      <td>0.748994</td>\n",
       "      <td>0.742089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression - Oversampled</td>\n",
       "      <td>0.748994</td>\n",
       "      <td>0.742089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression - Undersampled</td>\n",
       "      <td>0.748994</td>\n",
       "      <td>0.742089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.741754</td>\n",
       "      <td>0.736611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.629626</td>\n",
       "      <td>0.570077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  Accuracy Score  F1 Score\n",
       "0                 Logistic Regression        0.787409  0.783536\n",
       "1             Support Vector Machines        0.752212  0.751783\n",
       "2                      XG Boost Model        0.748994  0.742089\n",
       "3   Logistic Regression - Oversampled        0.748994  0.742089\n",
       "4  Logistic Regression - Undersampled        0.748994  0.742089\n",
       "5                         Naive Bayes        0.741754  0.736611\n",
       "6                       Random Forest        0.629626  0.570077"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Support Vector Machines', 'XG Boost Model', 'Logistic Regression - Oversampled', \n",
    "              'Logistic Regression - Undersampled', 'Naive Bayes', 'Random Forest'],\n",
    "    'Accuracy Score': [acc_lr, acc_svm, acc_xgb, acc_os_lr, acc_us_lr, acc_mnb, acc_rf],\n",
    "    'F1 Score': [f1_lr, f1_svm, f1_xgb, f1_os_lr, f1_us_lr, f1_mnb, f1_rf]})\n",
    "models.sort_values(by = 'Accuracy Score', ascending = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5db968608ecdb27000edf98c5f63e9ccc25d479a7a16895421f990979c50088b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
